{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_planets = pd.read_csv('../clean_planet_data/rand_non_null_planets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kep3 = pd.read_csv('../clean_planet_data/clean_cut_kepc3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2c1 = pd.read_csv('../clean_planet_data/clean_cut_k2c1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4_kep = pd.read_csv('../clean_planet_data/clean_kep_c4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_confirmed = pd.read_csv('../clean_planet_data/all_planets_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove last line from c4_kep because it has too many nulls:\n",
    "c4_kep.drop(index=7713, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sure there are transits in the confirmed planets set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4_kep['1'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4148</th>\n",
       "      <th>4149</th>\n",
       "      <th>4150</th>\n",
       "      <th>4151</th>\n",
       "      <th>4152</th>\n",
       "      <th>4153</th>\n",
       "      <th>4154</th>\n",
       "      <th>4155</th>\n",
       "      <th>4156</th>\n",
       "      <th>4157</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KIC 1025494</td>\n",
       "      <td>0</td>\n",
       "      <td>2.633382e+05</td>\n",
       "      <td>2.633437e+05</td>\n",
       "      <td>2.633493e+05</td>\n",
       "      <td>2.632883e+05</td>\n",
       "      <td>2.634034e+05</td>\n",
       "      <td>2.633153e+05</td>\n",
       "      <td>2.633076e+05</td>\n",
       "      <td>2.633548e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.633262e+05</td>\n",
       "      <td>2.633096e+05</td>\n",
       "      <td>2.633450e+05</td>\n",
       "      <td>2.633055e+05</td>\n",
       "      <td>2.633076e+05</td>\n",
       "      <td>2.633412e+05</td>\n",
       "      <td>2.633336e+05</td>\n",
       "      <td>2.633332e+05</td>\n",
       "      <td>2.633176e+05</td>\n",
       "      <td>2.633526e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KIC 1025578</td>\n",
       "      <td>0</td>\n",
       "      <td>1.292338e+04</td>\n",
       "      <td>1.292032e+04</td>\n",
       "      <td>1.291726e+04</td>\n",
       "      <td>1.291329e+04</td>\n",
       "      <td>1.292188e+04</td>\n",
       "      <td>1.292211e+04</td>\n",
       "      <td>1.291157e+04</td>\n",
       "      <td>1.292156e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.291279e+04</td>\n",
       "      <td>1.291749e+04</td>\n",
       "      <td>1.292433e+04</td>\n",
       "      <td>1.292121e+04</td>\n",
       "      <td>1.291119e+04</td>\n",
       "      <td>1.291699e+04</td>\n",
       "      <td>1.291756e+04</td>\n",
       "      <td>1.293214e+04</td>\n",
       "      <td>1.293186e+04</td>\n",
       "      <td>1.290860e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KIC 1025986</td>\n",
       "      <td>0</td>\n",
       "      <td>1.276864e+06</td>\n",
       "      <td>1.277048e+06</td>\n",
       "      <td>1.277233e+06</td>\n",
       "      <td>1.277410e+06</td>\n",
       "      <td>1.277653e+06</td>\n",
       "      <td>1.277849e+06</td>\n",
       "      <td>1.278068e+06</td>\n",
       "      <td>1.278165e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.272619e+06</td>\n",
       "      <td>1.273011e+06</td>\n",
       "      <td>1.273417e+06</td>\n",
       "      <td>1.273826e+06</td>\n",
       "      <td>1.274113e+06</td>\n",
       "      <td>1.274493e+06</td>\n",
       "      <td>1.274748e+06</td>\n",
       "      <td>1.275238e+06</td>\n",
       "      <td>1.275759e+06</td>\n",
       "      <td>1.276052e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KIC 1026032</td>\n",
       "      <td>0</td>\n",
       "      <td>1.743618e+04</td>\n",
       "      <td>1.743269e+04</td>\n",
       "      <td>1.742921e+04</td>\n",
       "      <td>1.743379e+04</td>\n",
       "      <td>1.743004e+04</td>\n",
       "      <td>1.743159e+04</td>\n",
       "      <td>1.742726e+04</td>\n",
       "      <td>1.742583e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.739245e+04</td>\n",
       "      <td>1.739575e+04</td>\n",
       "      <td>1.739241e+04</td>\n",
       "      <td>1.740589e+04</td>\n",
       "      <td>1.739701e+04</td>\n",
       "      <td>1.738893e+04</td>\n",
       "      <td>1.740034e+04</td>\n",
       "      <td>1.739358e+04</td>\n",
       "      <td>1.738954e+04</td>\n",
       "      <td>1.738559e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KIC 1026133</td>\n",
       "      <td>0</td>\n",
       "      <td>8.089427e+04</td>\n",
       "      <td>8.089823e+04</td>\n",
       "      <td>8.090219e+04</td>\n",
       "      <td>8.091389e+04</td>\n",
       "      <td>8.088692e+04</td>\n",
       "      <td>8.089593e+04</td>\n",
       "      <td>8.087595e+04</td>\n",
       "      <td>8.091329e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>8.090645e+04</td>\n",
       "      <td>8.092413e+04</td>\n",
       "      <td>8.089960e+04</td>\n",
       "      <td>8.091161e+04</td>\n",
       "      <td>8.090157e+04</td>\n",
       "      <td>8.090039e+04</td>\n",
       "      <td>8.092984e+04</td>\n",
       "      <td>8.091438e+04</td>\n",
       "      <td>8.091408e+04</td>\n",
       "      <td>8.090827e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  1             2             3             4             5  \\\n",
       "0  KIC 1025494  0  2.633382e+05  2.633437e+05  2.633493e+05  2.632883e+05   \n",
       "1  KIC 1025578  0  1.292338e+04  1.292032e+04  1.291726e+04  1.291329e+04   \n",
       "2  KIC 1025986  0  1.276864e+06  1.277048e+06  1.277233e+06  1.277410e+06   \n",
       "3  KIC 1026032  0  1.743618e+04  1.743269e+04  1.742921e+04  1.743379e+04   \n",
       "4  KIC 1026133  0  8.089427e+04  8.089823e+04  8.090219e+04  8.091389e+04   \n",
       "\n",
       "              6             7             8             9      ...       \\\n",
       "0  2.634034e+05  2.633153e+05  2.633076e+05  2.633548e+05      ...        \n",
       "1  1.292188e+04  1.292211e+04  1.291157e+04  1.292156e+04      ...        \n",
       "2  1.277653e+06  1.277849e+06  1.278068e+06  1.278165e+06      ...        \n",
       "3  1.743004e+04  1.743159e+04  1.742726e+04  1.742583e+04      ...        \n",
       "4  8.088692e+04  8.089593e+04  8.087595e+04  8.091329e+04      ...        \n",
       "\n",
       "           4148          4149          4150          4151          4152  \\\n",
       "0  2.633262e+05  2.633096e+05  2.633450e+05  2.633055e+05  2.633076e+05   \n",
       "1  1.291279e+04  1.291749e+04  1.292433e+04  1.292121e+04  1.291119e+04   \n",
       "2  1.272619e+06  1.273011e+06  1.273417e+06  1.273826e+06  1.274113e+06   \n",
       "3  1.739245e+04  1.739575e+04  1.739241e+04  1.740589e+04  1.739701e+04   \n",
       "4  8.090645e+04  8.092413e+04  8.089960e+04  8.091161e+04  8.090157e+04   \n",
       "\n",
       "           4153          4154          4155          4156          4157  \n",
       "0  2.633412e+05  2.633336e+05  2.633332e+05  2.633176e+05  2.633526e+05  \n",
       "1  1.291699e+04  1.291756e+04  1.293214e+04  1.293186e+04  1.290860e+04  \n",
       "2  1.274493e+06  1.274748e+06  1.275238e+06  1.275759e+06  1.276052e+06  \n",
       "3  1.738893e+04  1.740034e+04  1.739358e+04  1.738954e+04  1.738559e+04  \n",
       "4  8.090039e+04  8.092984e+04  8.091438e+04  8.091408e+04  8.090827e+04  \n",
       "\n",
       "[5 rows x 4158 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c4_kep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "KIC 10000941  found @ index:  174 orbital period:  3.5047Â±0.0000\n",
      "250\n",
      "KIC 10002866  found @ index:  265 orbital period:  3.9370Â±0.0000\n",
      "KIC 10002866  found @ index:  265 orbital period:  28.0819Â±0.0001\n",
      "KIC 10002866  found @ index:  265 orbital period:  10.0888Â±0.0000\n",
      "KIC 10004519  found @ index:  328 orbital period:  9.8032Â±0.0000\n",
      "KIC 10004738  found @ index:  338 orbital period:  56.4754Â±0.0002\n",
      "KIC 10004738  found @ index:  338 orbital period:  92.8761Â±0.0008\n",
      "KIC 10004738  found @ index:  338 orbital period:  13.9307Â±0.0001\n",
      "KIC 10005788  found @ index:  398 orbital period:  10.9947Â±0.0000\n",
      "KIC 10006581  found @ index:  430 orbital period:  40.1100Â±0.0002\n",
      "500\n",
      "KIC 10010440  found @ index:  502 orbital period:  53.5991Â±0.0004\n",
      "KIC 10018233  found @ index:  691 orbital period:  16.2960Â±0.0001\n",
      "KIC 10019065  found @ index:  744 orbital period:  52.6298Â±0.0003\n",
      "750\n",
      "KIC 10019643  found @ index:  771 orbital period:  21.3473Â±0.0001\n",
      "KIC 10019643  found @ index:  771 orbital period:  7.8109Â±0.0001\n",
      "KIC 10019708  found @ index:  777 orbital period:  3.2687Â±0.0000\n",
      "KIC 10022908  found @ index:  821 orbital period:  6.9913Â±0.0000\n",
      "KIC 10024051  found @ index:  872 orbital period:  0.5774Â±0.0000\n",
      "KIC 10024701  found @ index:  905 orbital period:  14.3751Â±0.0000\n",
      "KIC 10024862  found @ index:  913 on 2nd level of loop orbital period:  567.04Â±0.03\n",
      "KIC 10026502  found @ index:  986 orbital period:  101.9518Â±0.0016\n",
      "1000\n",
      "KIC 10027247  found @ index:  1028 orbital period:  86.8290Â±0.0011\n",
      "KIC 10027323  found @ index:  1032 orbital period:  5.9237Â±0.0000\n",
      "KIC 10027323  found @ index:  1032 orbital period:  105.3564Â±0.0009\n",
      "KIC 10028535  found @ index:  1091 orbital period:  0.6631Â±0.0000\n",
      "KIC 10028792  found @ index:  1099 orbital period:  114.7309Â±0.0005\n",
      "KIC 10028792  found @ index:  1099 orbital period:  192.36Â±0.07\n",
      "1250\n",
      "KIC 10055126  found @ index:  1352 orbital period:  9.1761Â±0.0001\n",
      "KIC 10055126  found @ index:  1352 orbital period:  19.7383Â±0.0002\n",
      "KIC 10057494  found @ index:  1426 orbital period:  2.4181Â±0.0000\n",
      "KIC 10059645  found @ index:  1493 orbital period:  6.4944Â±0.0000\n",
      "1500\n",
      "KIC 10063208  found @ index:  1525 orbital period:  9.3281Â±0.0001\n",
      "KIC 10063802  found @ index:  1553 orbital period:  120.0181Â±0.0004\n",
      "1750\n",
      "KIC 10068659  found @ index:  1779 orbital period:  11.4769Â±0.0001\n",
      "KIC 10070468  found @ index:  1850 orbital period:  1.6819Â±0.0000\n",
      "2000\n",
      "KIC 10080248  found @ index:  2052 orbital period:  14.8783Â±0.0001\n",
      "2250\n",
      "KIC 10089911  found @ index:  2406 orbital period:  6.9671Â±0.0000\n",
      "2500\n",
      "KIC 10098844  found @ index:  2724 orbital period:  47.4500Â±0.0008\n",
      "2750\n",
      "KIC 10122255  found @ index:  2860 orbital period:  27.6655Â±0.0001\n",
      "KIC 10123064  found @ index:  2890 orbital period:  4.2437Â±0.0000\n",
      "3000\n",
      "KIC 10130039  found @ index:  3037 orbital period:  12.7580Â±0.0001\n",
      "KIC 10130039  found @ index:  3037 orbital period:  5.4703Â±0.0000\n",
      "KIC 10130039  found @ index:  3037 orbital period:  25.0985Â±0.0001\n",
      "KIC 10132832  found @ index:  3129 orbital period:  16.0768Â±0.0001\n",
      "3250\n",
      "KIC 10136549  found @ index:  3262 orbital period:  9.6932Â±0.0000\n",
      "KIC 10136549  found @ index:  3262 orbital period:  3.2928Â±0.0000\n",
      "KIC 10141900  found @ index:  3410 orbital period:  1.1966Â±0.0000\n",
      "3500\n",
      "KIC 10153855  found @ index:  3677 orbital period:  1.0638Â±0.0000\n",
      "KIC 10154388  found @ index:  3707 orbital period:  12.0622Â±0.0000\n",
      "3750\n",
      "KIC 10157458  found @ index:  3864 orbital period:  7.3368Â±0.0000\n",
      "KIC 10158729  found @ index:  3926 orbital period:  58.6018Â±0.0006\n",
      "4000\n",
      "KIC 10166274  found @ index:  4124 orbital period:  3.3537Â±0.0000\n",
      "KIC 10166274  found @ index:  4124 orbital period:  6.8774Â±0.0000\n",
      "KIC 10166274  found @ index:  4124 orbital period:  28.4645Â±0.0002\n",
      "KIC 10187017  found @ index:  4200 orbital period:  16.15\n",
      "KIC 10187017  found @ index:  4200 orbital period:  10.31\n",
      "KIC 10187017  found @ index:  4200 orbital period:  27.5\n",
      "KIC 10187017  found @ index:  4200 orbital period:  7.07\n",
      "KIC 10187017  found @ index:  4200 orbital period:  5.29\n",
      "KIC 10187159  found @ index:  4206 orbital period:  7.9643Â±0.0000\n",
      "4250\n",
      "KIC 10189546  found @ index:  4304 orbital period:  42.9496Â±0.0002\n",
      "KIC 10189546  found @ index:  4304 orbital period:  117.0405Â±0.0018\n",
      "KIC 10190777  found @ index:  4342 orbital period:  1.4112Â±0.0000\n",
      "4500\n",
      "KIC 10203349  found @ index:  4726 orbital period:  17.1465Â±0.0001\n",
      "4750\n",
      "KIC 10212441  found @ index:  4862 orbital period:  15.0447Â±0.0001\n",
      "KIC 10213902  found @ index:  4917 orbital period:  59.6225Â±0.0003\n",
      "KIC 10214162  found @ index:  4936 orbital period:  17.4240Â±0.0001\n",
      "5000\n",
      "5250\n",
      "5500\n",
      "KIC 10253547  found @ index:  5557 orbital period:  59.9806Â±0.0009\n",
      "KIC 10253547  found @ index:  5557 orbital period:  25.7457Â±0.0005\n",
      "5750\n",
      "KIC 10264660  found @ index:  5896 orbital period:  6.79\n",
      "KIC 10265898  found @ index:  5941 orbital period:  1.2603Â±0.0000\n",
      "KIC 10266615  found @ index:  5968 orbital period:  10.9403Â±0.0000\n",
      "6000\n",
      "KIC 10271806  found @ index:  6068 orbital period:  5.9250Â±0.0000\n",
      "KIC 10271806  found @ index:  6068 orbital period:  11.3494Â±0.0000\n",
      "KIC 10271806  found @ index:  6068 orbital period:  3.1329Â±0.0000\n",
      "KIC 10271806  found @ index:  6068 orbital period:  18.6436Â±0.0001\n",
      "KIC 10272442  found @ index:  6086 orbital period:  24.5435Â±0.0001\n",
      "KIC 10272640  found @ index:  6092 orbital period:  3.7706Â±0.0000\n",
      "6250\n",
      "KIC 10285631  found @ index:  6412 orbital period:  18.6840Â±0.0001\n",
      "6500\n",
      "KIC 10289119  found @ index:  6584 orbital period:  16.1047Â±0.0001\n",
      "KIC 10290666  found @ index:  6649 orbital period:  5.4585Â±0.0000\n",
      "6750\n",
      "KIC 10318874  found @ index:  6892 orbital period:  2.51\n",
      "KIC 10318874  found @ index:  6892 orbital period:  820Â±3\n",
      "7000\n",
      "KIC 10328393  found @ index:  7125 orbital period:  7.6263Â±0.0000\n",
      "KIC 10328393  found @ index:  7125 orbital period:  15.9956Â±0.0001\n",
      "KIC 10328393  found @ index:  7125 orbital period:  34.2115Â±0.0003\n",
      "KIC 10328458  found @ index:  7131 orbital period:  2.3523Â±0.0000\n",
      "KIC 10329196  found @ index:  7167 orbital period:  85.7565Â±0.0006\n",
      "KIC 10329469  found @ index:  7180 orbital period:  55.8227Â±0.0004\n",
      "KIC 10329835  found @ index:  7192 orbital period:  1.5237Â±0.0000\n",
      "KIC 10330115  found @ index:  7204 orbital period:  13.2141Â±0.0000\n",
      "7250\n",
      "KIC 10332883  found @ index:  7329 orbital period:  1.1512Â±0.0000\n",
      "KIC 10337258  found @ index:  7411 orbital period:  13.2854Â±0.0000\n",
      "KIC 10337517  found @ index:  7423 orbital period:  4.2926Â±0.0000\n",
      "7500\n",
      "KIC 10340423  found @ index:  7526 orbital period:  18.7942Â±0.0001\n",
      "KIC 10340423  found @ index:  7526 orbital period:  6.7390Â±0.0000\n",
      "KIC 10350571  found @ index:  7697 orbital period:  31.5923Â±0.0007\n"
     ]
    }
   ],
   "source": [
    "# cut off the confidence interval, char before + or +-\n",
    "#     regex?\n",
    "\n",
    "# for each star in confirmed planet light curve set\n",
    "#     find the row with the same star name\n",
    "#         see if orbit > 66 days\n",
    "#             drop that biz\n",
    "\n",
    "# print something out if there are no matches\n",
    "\n",
    "# make a list of indexs and then drop them in another cell?\n",
    "# be careful of multiplanetary systems, I don't want to drop it if one planet has a long period and another one works\n",
    "\n",
    "# if it starts with > or < then treat it like it has too long a period, after looking at all of them, I know this to be the case\n",
    "\n",
    "# re.findall(r'Executive: .+', string)\n",
    "\n",
    "not_found = 0\n",
    "stars_to_drop = []\n",
    "\n",
    "for j in range(len(c4_kep)): # for every light curve from has_planets\n",
    "    if j % 250 == 0:\n",
    "        print(j)\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(all_confirmed)): # look through each star name in the list of all confirmed planets\n",
    "        try:\n",
    "            if all_confirmed.loc[i, 'Alternative star names'].find(c4_kep.iloc[j, 0]) != -1:\n",
    "#                 print(all_confirmed.loc[i, 'Orbital period [days]'])\n",
    "                count += 1\n",
    "                print(c4_kep.iloc[j, 0], ' found @ index: ', j, 'orbital period: ', all_confirmed.loc[i, 'Orbital period [days]'])\n",
    "                c4_kep.loc[j, '1'] = 1\n",
    "    \n",
    "\n",
    "#                 print(re.findall(r'\\d\\d\\d', all_confirmed.loc[i, 'Orbital period [days]']))\n",
    "                \n",
    "#                 if all_confirmed.loc[i, 'Orbital period [days]'] > 60:\n",
    "#                     stars_to_drop.append(has_planets.iloc[j, 0])\n",
    "                \n",
    "    #                 continue\n",
    "    #             else:\n",
    "    #                 print('Nooooooope')\n",
    "        except AttributeError: # if the alternate star names value are null\n",
    "            try:\n",
    "                if all_confirmed.loc[i, 'Star name'].find(c4_kep.iloc[j, 0]) != -1:\n",
    "#                     print(all_confirmed.loc[i, 'Orbital period [days]'])\n",
    "                    count += 1\n",
    "                    print(c4_kep.iloc[j, 0], ' found @ index: ', j, 'on 2nd level of loop', 'orbital period: ', all_confirmed.loc[i, 'Orbital period [days]'])\n",
    "                    c4_kep.loc[j, '1'] = 1\n",
    "                    \n",
    "#                 if all_confirmed.loc[i, 'Orbital period [days]'] > 60:\n",
    "#                     stars_to_drop.append(has_planets.iloc[j, 0])\n",
    "                    \n",
    "    #                     continue\n",
    "    #                 else:\n",
    "    #                     print('Nooooooope')\n",
    "            except AttributeError: # if this is null too, keep going\n",
    "#                 print('Star name not found due to nulls: ', has_planets.iloc[j, 0])\n",
    "                continue\n",
    "    if count == 0:\n",
    "        not_found += 1\n",
    "#         stars_to_drop.append(has_planets.iloc[j, 0])\n",
    "#         print(not_found, 'Star name not found in all_confirmed df', has_planets.iloc[j, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7642\n",
       "1      71\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c4_kep['1'].value_counts() # I counted only 5 stars with no planets with an orbit under 60 days in this set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primary planet name</th>\n",
       "      <th>Radius [Rearth]</th>\n",
       "      <th>Distance [lightyears]</th>\n",
       "      <th>Orbital period [days]</th>\n",
       "      <th>Number of stars in system</th>\n",
       "      <th>Primary system name</th>\n",
       "      <th>Radius [RSun]</th>\n",
       "      <th>Number of planets in system</th>\n",
       "      <th>Mass [Mearth]</th>\n",
       "      <th>Star name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Age [Gyr]</th>\n",
       "      <th>Mass [Mjup]</th>\n",
       "      <th>Mass [MSun]</th>\n",
       "      <th>Radius [Rjup]</th>\n",
       "      <th>Alternative system names</th>\n",
       "      <th>Alternative planet names</th>\n",
       "      <th>Discovery method</th>\n",
       "      <th>Alternative star names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KOI-1843.03</td>\n",
       "      <td>0.61+0.12âˆ’0.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1769Â±0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>KOI-1843</td>\n",
       "      <td>0.50Â±0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.44+0.38âˆ’0.16</td>\n",
       "      <td>KOI-1843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0014+0.0012âˆ’0.0005</td>\n",
       "      <td>0.52Â±0.02</td>\n",
       "      <td>0.054+0.011âˆ’0.007</td>\n",
       "      <td>Kepler-974, KIC 5080636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>transit</td>\n",
       "      <td>Kepler-974, KIC 5080636, 2MASS J19000314+4013147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Primary planet name Radius [Rearth] Distance [lightyears]  \\\n",
       "0         KOI-1843.03  0.61+0.12âˆ’0.08                   NaN   \n",
       "\n",
       "  Orbital period [days]  Number of stars in system Primary system name  \\\n",
       "0         0.1769Â±0.0000                          1            KOI-1843   \n",
       "\n",
       "  Radius [RSun]  Number of planets in system   Mass [Mearth] Star name  \\\n",
       "0     0.50Â±0.02                            3  0.44+0.38âˆ’0.16  KOI-1843   \n",
       "\n",
       "  Description Age [Gyr]           Mass [Mjup] Mass [MSun]      Radius [Rjup]  \\\n",
       "0         NaN       NaN  0.0014+0.0012âˆ’0.0005   0.52Â±0.02  0.054+0.011âˆ’0.007   \n",
       "\n",
       "  Alternative system names Alternative planet names Discovery method  \\\n",
       "0  Kepler-974, KIC 5080636                      NaN          transit   \n",
       "\n",
       "                             Alternative star names  \n",
       "0  Kepler-974, KIC 5080636, 2MASS J19000314+4013147  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_confirmed.head(1) #['Orbital period [days]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Training Set:\n",
    "Mixing confirmed planets into data so the model can learn what they are like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5087, 3199)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kep3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4550, 3199)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k2c1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1166, 3915)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_planets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1166, 3199)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cut out the extra data to compare across the same timeline\n",
    "join_planets = has_planets.iloc[:,:3199]\n",
    "join_planets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split c4_kep to add to training data\n",
    "to_train_on = c4_kep.head(2714).iloc[:,:3199]\n",
    "to_train_on.columns = kep3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set aside a holdout set\n",
    "c4_holdout = c4_kep.tail(5000).iloc[:,:3199]\n",
    "c4_holdout.columns = kep3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure columns are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>KIC 10098201</td>\n",
       "      <td>0</td>\n",
       "      <td>30738.531250</td>\n",
       "      <td>30734.998047</td>\n",
       "      <td>30731.464844</td>\n",
       "      <td>30744.189453</td>\n",
       "      <td>30737.357422</td>\n",
       "      <td>30725.398438</td>\n",
       "      <td>30727.322266</td>\n",
       "      <td>30740.234375</td>\n",
       "      <td>...</td>\n",
       "      <td>30711.484375</td>\n",
       "      <td>30708.513672</td>\n",
       "      <td>30704.792969</td>\n",
       "      <td>30716.123047</td>\n",
       "      <td>30719.189453</td>\n",
       "      <td>30699.626953</td>\n",
       "      <td>30704.642578</td>\n",
       "      <td>30691.193359</td>\n",
       "      <td>30720.410156</td>\n",
       "      <td>30690.033203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>KIC 10098203</td>\n",
       "      <td>0</td>\n",
       "      <td>60630.570312</td>\n",
       "      <td>60635.128906</td>\n",
       "      <td>60639.687500</td>\n",
       "      <td>60641.605469</td>\n",
       "      <td>60621.882812</td>\n",
       "      <td>60631.457031</td>\n",
       "      <td>60631.242188</td>\n",
       "      <td>60605.812500</td>\n",
       "      <td>...</td>\n",
       "      <td>60652.035156</td>\n",
       "      <td>60639.867188</td>\n",
       "      <td>60622.761719</td>\n",
       "      <td>60637.054688</td>\n",
       "      <td>60635.718750</td>\n",
       "      <td>60629.484375</td>\n",
       "      <td>60627.082031</td>\n",
       "      <td>60625.492188</td>\n",
       "      <td>60633.804688</td>\n",
       "      <td>60645.210938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>KIC 10098322</td>\n",
       "      <td>0</td>\n",
       "      <td>54474.214844</td>\n",
       "      <td>54476.830078</td>\n",
       "      <td>54479.445312</td>\n",
       "      <td>54454.609375</td>\n",
       "      <td>54465.417969</td>\n",
       "      <td>54467.019531</td>\n",
       "      <td>54482.117188</td>\n",
       "      <td>54474.449219</td>\n",
       "      <td>...</td>\n",
       "      <td>54470.093750</td>\n",
       "      <td>54471.281250</td>\n",
       "      <td>54482.734375</td>\n",
       "      <td>54473.542969</td>\n",
       "      <td>54476.136719</td>\n",
       "      <td>54466.660156</td>\n",
       "      <td>54478.226562</td>\n",
       "      <td>54475.183594</td>\n",
       "      <td>54473.289062</td>\n",
       "      <td>54458.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>KIC 10098323</td>\n",
       "      <td>0</td>\n",
       "      <td>19490.130859</td>\n",
       "      <td>19477.936523</td>\n",
       "      <td>19465.742188</td>\n",
       "      <td>19469.632812</td>\n",
       "      <td>19500.746094</td>\n",
       "      <td>19472.207031</td>\n",
       "      <td>19483.044922</td>\n",
       "      <td>19470.707031</td>\n",
       "      <td>...</td>\n",
       "      <td>19498.857422</td>\n",
       "      <td>19487.326172</td>\n",
       "      <td>19500.484375</td>\n",
       "      <td>19512.279297</td>\n",
       "      <td>19482.585938</td>\n",
       "      <td>19481.179688</td>\n",
       "      <td>19476.701172</td>\n",
       "      <td>19475.287109</td>\n",
       "      <td>19492.650391</td>\n",
       "      <td>19495.101562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>KIC 10098534</td>\n",
       "      <td>0</td>\n",
       "      <td>12773.138672</td>\n",
       "      <td>12770.885254</td>\n",
       "      <td>12768.631836</td>\n",
       "      <td>12776.298828</td>\n",
       "      <td>12772.017578</td>\n",
       "      <td>12771.841797</td>\n",
       "      <td>12779.006836</td>\n",
       "      <td>12782.492188</td>\n",
       "      <td>...</td>\n",
       "      <td>12771.104492</td>\n",
       "      <td>12784.988281</td>\n",
       "      <td>12774.524414</td>\n",
       "      <td>12778.074219</td>\n",
       "      <td>12769.102539</td>\n",
       "      <td>12787.123047</td>\n",
       "      <td>12773.678711</td>\n",
       "      <td>12776.996094</td>\n",
       "      <td>12765.583008</td>\n",
       "      <td>12781.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  LABEL        FLUX.1        FLUX.2        FLUX.3  \\\n",
       "2709  KIC 10098201      0  30738.531250  30734.998047  30731.464844   \n",
       "2710  KIC 10098203      0  60630.570312  60635.128906  60639.687500   \n",
       "2711  KIC 10098322      0  54474.214844  54476.830078  54479.445312   \n",
       "2712  KIC 10098323      0  19490.130859  19477.936523  19465.742188   \n",
       "2713  KIC 10098534      0  12773.138672  12770.885254  12768.631836   \n",
       "\n",
       "            FLUX.4        FLUX.5        FLUX.6        FLUX.7        FLUX.8  \\\n",
       "2709  30744.189453  30737.357422  30725.398438  30727.322266  30740.234375   \n",
       "2710  60641.605469  60621.882812  60631.457031  60631.242188  60605.812500   \n",
       "2711  54454.609375  54465.417969  54467.019531  54482.117188  54474.449219   \n",
       "2712  19469.632812  19500.746094  19472.207031  19483.044922  19470.707031   \n",
       "2713  12776.298828  12772.017578  12771.841797  12779.006836  12782.492188   \n",
       "\n",
       "          ...          FLUX.3188     FLUX.3189     FLUX.3190     FLUX.3191  \\\n",
       "2709      ...       30711.484375  30708.513672  30704.792969  30716.123047   \n",
       "2710      ...       60652.035156  60639.867188  60622.761719  60637.054688   \n",
       "2711      ...       54470.093750  54471.281250  54482.734375  54473.542969   \n",
       "2712      ...       19498.857422  19487.326172  19500.484375  19512.279297   \n",
       "2713      ...       12771.104492  12784.988281  12774.524414  12778.074219   \n",
       "\n",
       "         FLUX.3192     FLUX.3193     FLUX.3194     FLUX.3195     FLUX.3196  \\\n",
       "2709  30719.189453  30699.626953  30704.642578  30691.193359  30720.410156   \n",
       "2710  60635.718750  60629.484375  60627.082031  60625.492188  60633.804688   \n",
       "2711  54476.136719  54466.660156  54478.226562  54475.183594  54473.289062   \n",
       "2712  19482.585938  19481.179688  19476.701172  19475.287109  19492.650391   \n",
       "2713  12769.102539  12787.123047  12773.678711  12776.996094  12765.583008   \n",
       "\n",
       "         FLUX.3197  \n",
       "2709  30690.033203  \n",
       "2710  60645.210938  \n",
       "2711  54458.718750  \n",
       "2712  19495.101562  \n",
       "2713  12781.500000  \n",
       "\n",
       "[5 rows x 3199 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_train_on.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7708</th>\n",
       "      <td>KIC 10350884</td>\n",
       "      <td>0</td>\n",
       "      <td>11319.682617</td>\n",
       "      <td>11319.583008</td>\n",
       "      <td>11319.483398</td>\n",
       "      <td>11327.371094</td>\n",
       "      <td>11326.530273</td>\n",
       "      <td>11322.001953</td>\n",
       "      <td>11325.246094</td>\n",
       "      <td>11317.274414</td>\n",
       "      <td>...</td>\n",
       "      <td>11315.725586</td>\n",
       "      <td>11318.500000</td>\n",
       "      <td>11325.413086</td>\n",
       "      <td>11309.351562</td>\n",
       "      <td>11320.790039</td>\n",
       "      <td>11326.581055</td>\n",
       "      <td>11316.476562</td>\n",
       "      <td>11317.428711</td>\n",
       "      <td>11312.616211</td>\n",
       "      <td>11308.830078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7709</th>\n",
       "      <td>KIC 10350885</td>\n",
       "      <td>0</td>\n",
       "      <td>7623.983398</td>\n",
       "      <td>7621.442383</td>\n",
       "      <td>7618.901367</td>\n",
       "      <td>7619.235352</td>\n",
       "      <td>7622.194824</td>\n",
       "      <td>7621.204590</td>\n",
       "      <td>7620.562500</td>\n",
       "      <td>7613.972168</td>\n",
       "      <td>...</td>\n",
       "      <td>7621.973633</td>\n",
       "      <td>7616.027832</td>\n",
       "      <td>7616.118164</td>\n",
       "      <td>7619.416504</td>\n",
       "      <td>7613.662109</td>\n",
       "      <td>7627.311523</td>\n",
       "      <td>7616.322266</td>\n",
       "      <td>7626.585449</td>\n",
       "      <td>7626.179688</td>\n",
       "      <td>7629.745117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7710</th>\n",
       "      <td>KIC 10350897</td>\n",
       "      <td>0</td>\n",
       "      <td>26916.777344</td>\n",
       "      <td>26915.885742</td>\n",
       "      <td>26914.994141</td>\n",
       "      <td>26919.958984</td>\n",
       "      <td>26918.572266</td>\n",
       "      <td>26908.222656</td>\n",
       "      <td>26908.228516</td>\n",
       "      <td>26914.849609</td>\n",
       "      <td>...</td>\n",
       "      <td>26923.214844</td>\n",
       "      <td>26925.933594</td>\n",
       "      <td>26918.978516</td>\n",
       "      <td>26909.220703</td>\n",
       "      <td>26917.160156</td>\n",
       "      <td>26926.078125</td>\n",
       "      <td>26914.830078</td>\n",
       "      <td>26917.787109</td>\n",
       "      <td>26912.976562</td>\n",
       "      <td>26912.085938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7711</th>\n",
       "      <td>KIC 10350908</td>\n",
       "      <td>0</td>\n",
       "      <td>34512.160156</td>\n",
       "      <td>34508.902344</td>\n",
       "      <td>34505.644531</td>\n",
       "      <td>34503.800781</td>\n",
       "      <td>34504.421875</td>\n",
       "      <td>34504.312500</td>\n",
       "      <td>34496.136719</td>\n",
       "      <td>34519.199219</td>\n",
       "      <td>...</td>\n",
       "      <td>34472.511719</td>\n",
       "      <td>34473.394531</td>\n",
       "      <td>34470.164062</td>\n",
       "      <td>34480.593750</td>\n",
       "      <td>34477.785156</td>\n",
       "      <td>34483.500000</td>\n",
       "      <td>34481.949219</td>\n",
       "      <td>34485.648438</td>\n",
       "      <td>34477.027344</td>\n",
       "      <td>34469.027344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7712</th>\n",
       "      <td>KIC 10350930</td>\n",
       "      <td>0</td>\n",
       "      <td>36407.671875</td>\n",
       "      <td>36406.587891</td>\n",
       "      <td>36405.503906</td>\n",
       "      <td>36404.976562</td>\n",
       "      <td>36405.671875</td>\n",
       "      <td>36413.835938</td>\n",
       "      <td>36398.070312</td>\n",
       "      <td>36407.812500</td>\n",
       "      <td>...</td>\n",
       "      <td>36400.039062</td>\n",
       "      <td>36392.707031</td>\n",
       "      <td>36405.394531</td>\n",
       "      <td>36406.496094</td>\n",
       "      <td>36397.617188</td>\n",
       "      <td>36407.972656</td>\n",
       "      <td>36405.117188</td>\n",
       "      <td>36405.535156</td>\n",
       "      <td>36406.671875</td>\n",
       "      <td>36400.117188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  LABEL        FLUX.1        FLUX.2        FLUX.3  \\\n",
       "7708  KIC 10350884      0  11319.682617  11319.583008  11319.483398   \n",
       "7709  KIC 10350885      0   7623.983398   7621.442383   7618.901367   \n",
       "7710  KIC 10350897      0  26916.777344  26915.885742  26914.994141   \n",
       "7711  KIC 10350908      0  34512.160156  34508.902344  34505.644531   \n",
       "7712  KIC 10350930      0  36407.671875  36406.587891  36405.503906   \n",
       "\n",
       "            FLUX.4        FLUX.5        FLUX.6        FLUX.7        FLUX.8  \\\n",
       "7708  11327.371094  11326.530273  11322.001953  11325.246094  11317.274414   \n",
       "7709   7619.235352   7622.194824   7621.204590   7620.562500   7613.972168   \n",
       "7710  26919.958984  26918.572266  26908.222656  26908.228516  26914.849609   \n",
       "7711  34503.800781  34504.421875  34504.312500  34496.136719  34519.199219   \n",
       "7712  36404.976562  36405.671875  36413.835938  36398.070312  36407.812500   \n",
       "\n",
       "          ...          FLUX.3188     FLUX.3189     FLUX.3190     FLUX.3191  \\\n",
       "7708      ...       11315.725586  11318.500000  11325.413086  11309.351562   \n",
       "7709      ...        7621.973633   7616.027832   7616.118164   7619.416504   \n",
       "7710      ...       26923.214844  26925.933594  26918.978516  26909.220703   \n",
       "7711      ...       34472.511719  34473.394531  34470.164062  34480.593750   \n",
       "7712      ...       36400.039062  36392.707031  36405.394531  36406.496094   \n",
       "\n",
       "         FLUX.3192     FLUX.3193     FLUX.3194     FLUX.3195     FLUX.3196  \\\n",
       "7708  11320.790039  11326.581055  11316.476562  11317.428711  11312.616211   \n",
       "7709   7613.662109   7627.311523   7616.322266   7626.585449   7626.179688   \n",
       "7710  26917.160156  26926.078125  26914.830078  26917.787109  26912.976562   \n",
       "7711  34477.785156  34483.500000  34481.949219  34485.648438  34477.027344   \n",
       "7712  36397.617188  36407.972656  36405.117188  36405.535156  36406.671875   \n",
       "\n",
       "         FLUX.3197  \n",
       "7708  11308.830078  \n",
       "7709   7629.745117  \n",
       "7710  26912.085938  \n",
       "7711  34469.027344  \n",
       "7712  36400.117188  \n",
       "\n",
       "[5 rows x 3199 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c4_holdout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the dataframes have the same column names\n",
    "join_planets.columns = kep3.columns\n",
    "# k2c1.columns = kep3.columns\n",
    "\n",
    "# label the confirmed planet systems with 1\n",
    "join_planets['LABEL'] = 1\n",
    "# k2c1['LABEL'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KIC 10000941</td>\n",
       "      <td>1</td>\n",
       "      <td>52902.074219</td>\n",
       "      <td>52927.621094</td>\n",
       "      <td>52939.589844</td>\n",
       "      <td>52911.21875</td>\n",
       "      <td>52920.886719</td>\n",
       "      <td>52934.554688</td>\n",
       "      <td>52921.554688</td>\n",
       "      <td>52937.226562</td>\n",
       "      <td>...</td>\n",
       "      <td>50983.238281</td>\n",
       "      <td>50983.949219</td>\n",
       "      <td>50995.265625</td>\n",
       "      <td>50997.300781</td>\n",
       "      <td>50993.734375</td>\n",
       "      <td>51004.308594</td>\n",
       "      <td>50999.628906</td>\n",
       "      <td>51006.1875</td>\n",
       "      <td>51016.789062</td>\n",
       "      <td>51033.65625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 3199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  LABEL        FLUX.1        FLUX.2        FLUX.3       FLUX.4  \\\n",
       "0  KIC 10000941      1  52902.074219  52927.621094  52939.589844  52911.21875   \n",
       "\n",
       "         FLUX.5        FLUX.6        FLUX.7        FLUX.8     ...       \\\n",
       "0  52920.886719  52934.554688  52921.554688  52937.226562     ...        \n",
       "\n",
       "      FLUX.3188     FLUX.3189     FLUX.3190     FLUX.3191     FLUX.3192  \\\n",
       "0  50983.238281  50983.949219  50995.265625  50997.300781  50993.734375   \n",
       "\n",
       "      FLUX.3193     FLUX.3194   FLUX.3195     FLUX.3196    FLUX.3197  \n",
       "0  51004.308594  50999.628906  51006.1875  51016.789062  51033.65625  \n",
       "\n",
       "[1 rows x 3199 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_planets.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.1</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 3199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  LABEL  FLUX.1  FLUX.2  FLUX.3  FLUX.4  FLUX.5  FLUX.6  FLUX.7  \\\n",
       "0   NaN      1   93.85   83.81    20.1  -26.98  -39.56 -124.71 -135.18   \n",
       "\n",
       "   FLUX.8    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  FLUX.3192  \\\n",
       "0  -96.27    ...         -78.07    -102.15    -102.15      25.13      48.57   \n",
       "\n",
       "   FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      92.54      39.32      61.42       5.08     -39.54  \n",
       "\n",
       "[1 rows x 3199 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kep3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KIC 10000941</td>\n",
       "      <td>1</td>\n",
       "      <td>52902.074219</td>\n",
       "      <td>52927.621094</td>\n",
       "      <td>52939.589844</td>\n",
       "      <td>52911.21875</td>\n",
       "      <td>52920.886719</td>\n",
       "      <td>52934.554688</td>\n",
       "      <td>52921.554688</td>\n",
       "      <td>52937.226562</td>\n",
       "      <td>...</td>\n",
       "      <td>50983.238281</td>\n",
       "      <td>50983.949219</td>\n",
       "      <td>50995.265625</td>\n",
       "      <td>50997.300781</td>\n",
       "      <td>50993.734375</td>\n",
       "      <td>51004.308594</td>\n",
       "      <td>50999.628906</td>\n",
       "      <td>51006.1875</td>\n",
       "      <td>51016.789062</td>\n",
       "      <td>51033.65625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 3199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  LABEL        FLUX.1        FLUX.2        FLUX.3       FLUX.4  \\\n",
       "0  KIC 10000941      1  52902.074219  52927.621094  52939.589844  52911.21875   \n",
       "\n",
       "         FLUX.5        FLUX.6        FLUX.7        FLUX.8     ...       \\\n",
       "0  52920.886719  52934.554688  52921.554688  52937.226562     ...        \n",
       "\n",
       "      FLUX.3188     FLUX.3189     FLUX.3190     FLUX.3191     FLUX.3192  \\\n",
       "0  50983.238281  50983.949219  50995.265625  50997.300781  50993.734375   \n",
       "\n",
       "      FLUX.3193     FLUX.3194   FLUX.3195     FLUX.3196    FLUX.3197  \n",
       "0  51004.308594  50999.628906  51006.1875  51016.789062  51033.65625  \n",
       "\n",
       "[1 rows x 3199 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df = pd.concat([join_planets, to_train_on], axis = 0) #kep3 removed\n",
    "master_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3880, 3199)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2685\n",
       "1    1195\n",
       "Name: LABEL, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline accuracy\n",
    "val_count = master_df['LABEL'].value_counts()\n",
    "val_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3079896907216495"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_acc = val_count[1] / val_count.sum()\n",
    "base_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make X and y\n",
    "X = master_df.iloc[:, 2:]\n",
    "y = master_df['LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.T\n",
    "X_test = X_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2250</th>\n",
       "      <th>2388</th>\n",
       "      <th>277</th>\n",
       "      <th>308</th>\n",
       "      <th>2598</th>\n",
       "      <th>1659</th>\n",
       "      <th>1826</th>\n",
       "      <th>947</th>\n",
       "      <th>929</th>\n",
       "      <th>670</th>\n",
       "      <th>...</th>\n",
       "      <th>467</th>\n",
       "      <th>1542</th>\n",
       "      <th>1764</th>\n",
       "      <th>297</th>\n",
       "      <th>748</th>\n",
       "      <th>1672</th>\n",
       "      <th>2659</th>\n",
       "      <th>2313</th>\n",
       "      <th>2359</th>\n",
       "      <th>937</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FLUX.1</th>\n",
       "      <td>10622.535156</td>\n",
       "      <td>17328.193359</td>\n",
       "      <td>69057.796875</td>\n",
       "      <td>12952.023438</td>\n",
       "      <td>25843.052734</td>\n",
       "      <td>16255.761719</td>\n",
       "      <td>8148.277832</td>\n",
       "      <td>103458.59375</td>\n",
       "      <td>10676.199219</td>\n",
       "      <td>91632.921875</td>\n",
       "      <td>...</td>\n",
       "      <td>179436.765625</td>\n",
       "      <td>64976.109375</td>\n",
       "      <td>196240.03125</td>\n",
       "      <td>20471.943359</td>\n",
       "      <td>195854.40625</td>\n",
       "      <td>38576.753906</td>\n",
       "      <td>29060.341797</td>\n",
       "      <td>19422.755859</td>\n",
       "      <td>120465.335938</td>\n",
       "      <td>12836.451172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 2910 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                2250          2388          277           308           2598  \\\n",
       "FLUX.1  10622.535156  17328.193359  69057.796875  12952.023438  25843.052734   \n",
       "\n",
       "                1659         1826          947           929           670   \\\n",
       "FLUX.1  16255.761719  8148.277832  103458.59375  10676.199219  91632.921875   \n",
       "\n",
       "            ...                467           1542          1764          297   \\\n",
       "FLUX.1      ...       179436.765625  64976.109375  196240.03125  20471.943359   \n",
       "\n",
       "                748           1672          2659          2313           2359  \\\n",
       "FLUX.1  195854.40625  38576.753906  29060.341797  19422.755859  120465.335938   \n",
       "\n",
       "                937   \n",
       "FLUX.1  12836.451172  \n",
       "\n",
       "[1 rows x 2910 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>999</th>\n",
       "      <th>852</th>\n",
       "      <th>1974</th>\n",
       "      <th>2090</th>\n",
       "      <th>826</th>\n",
       "      <th>1726</th>\n",
       "      <th>2400</th>\n",
       "      <th>2485</th>\n",
       "      <th>1270</th>\n",
       "      <th>400</th>\n",
       "      <th>...</th>\n",
       "      <th>903</th>\n",
       "      <th>582</th>\n",
       "      <th>954</th>\n",
       "      <th>1853</th>\n",
       "      <th>693</th>\n",
       "      <th>1292</th>\n",
       "      <th>784</th>\n",
       "      <th>740</th>\n",
       "      <th>1580</th>\n",
       "      <th>952</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FLUX.1</th>\n",
       "      <td>9880.798828</td>\n",
       "      <td>12909.222656</td>\n",
       "      <td>16269.579102</td>\n",
       "      <td>499187.78125</td>\n",
       "      <td>150852.5</td>\n",
       "      <td>12304.670898</td>\n",
       "      <td>54922.261719</td>\n",
       "      <td>15879.013672</td>\n",
       "      <td>21589.730469</td>\n",
       "      <td>6260.233398</td>\n",
       "      <td>...</td>\n",
       "      <td>13748.826172</td>\n",
       "      <td>7701.056152</td>\n",
       "      <td>16517.556641</td>\n",
       "      <td>12235.956055</td>\n",
       "      <td>16096.495117</td>\n",
       "      <td>136535.375</td>\n",
       "      <td>28165.697266</td>\n",
       "      <td>7219.591797</td>\n",
       "      <td>11156.152344</td>\n",
       "      <td>49068.183594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 970 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               999           852           1974          2090      826   \\\n",
       "FLUX.1  9880.798828  12909.222656  16269.579102  499187.78125  150852.5   \n",
       "\n",
       "                1726          2400          2485          1270         400   \\\n",
       "FLUX.1  12304.670898  54922.261719  15879.013672  21589.730469  6260.233398   \n",
       "\n",
       "            ...               903          582           954           1853  \\\n",
       "FLUX.1      ...       13748.826172  7701.056152  16517.556641  12235.956055   \n",
       "\n",
       "                693         1292          784          740           1580  \\\n",
       "FLUX.1  16096.495117  136535.375  28165.697266  7219.591797  11156.152344   \n",
       "\n",
       "                952   \n",
       "FLUX.1  49068.183594  \n",
       "\n",
       "[1 rows x 970 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "ss = StandardScaler()\n",
    "\n",
    "scaled_df = ss.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(scaled_df, columns=X_train.columns)\n",
    "\n",
    "test_scaled_df = ss.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(test_scaled_df, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.T\n",
    "X_test = X_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3187</th>\n",
       "      <th>3188</th>\n",
       "      <th>3189</th>\n",
       "      <th>3190</th>\n",
       "      <th>3191</th>\n",
       "      <th>3192</th>\n",
       "      <th>3193</th>\n",
       "      <th>3194</th>\n",
       "      <th>3195</th>\n",
       "      <th>3196</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>-0.607318</td>\n",
       "      <td>-0.176849</td>\n",
       "      <td>0.253621</td>\n",
       "      <td>0.046283</td>\n",
       "      <td>0.363075</td>\n",
       "      <td>-0.908132</td>\n",
       "      <td>-1.057989</td>\n",
       "      <td>0.576840</td>\n",
       "      <td>-1.870078</td>\n",
       "      <td>-0.848080</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094942</td>\n",
       "      <td>-2.865447</td>\n",
       "      <td>0.187692</td>\n",
       "      <td>-1.064967</td>\n",
       "      <td>-0.248287</td>\n",
       "      <td>-1.223271</td>\n",
       "      <td>0.084114</td>\n",
       "      <td>-1.508292</td>\n",
       "      <td>-0.383636</td>\n",
       "      <td>-0.419630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>-0.672346</td>\n",
       "      <td>-0.549175</td>\n",
       "      <td>-0.426003</td>\n",
       "      <td>-0.188362</td>\n",
       "      <td>-0.460143</td>\n",
       "      <td>-0.086277</td>\n",
       "      <td>0.810065</td>\n",
       "      <td>0.190190</td>\n",
       "      <td>-0.758031</td>\n",
       "      <td>-0.484242</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227857</td>\n",
       "      <td>-0.370442</td>\n",
       "      <td>-1.295903</td>\n",
       "      <td>-0.782130</td>\n",
       "      <td>1.642813</td>\n",
       "      <td>-0.217147</td>\n",
       "      <td>-0.733932</td>\n",
       "      <td>0.615267</td>\n",
       "      <td>0.046936</td>\n",
       "      <td>0.254789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>-0.360273</td>\n",
       "      <td>0.213458</td>\n",
       "      <td>0.787189</td>\n",
       "      <td>0.297611</td>\n",
       "      <td>1.292560</td>\n",
       "      <td>1.262779</td>\n",
       "      <td>-0.010575</td>\n",
       "      <td>-0.145942</td>\n",
       "      <td>-0.829546</td>\n",
       "      <td>-1.702213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623846</td>\n",
       "      <td>-0.265967</td>\n",
       "      <td>-0.290333</td>\n",
       "      <td>0.151415</td>\n",
       "      <td>0.398234</td>\n",
       "      <td>0.448771</td>\n",
       "      <td>-0.828644</td>\n",
       "      <td>-1.029438</td>\n",
       "      <td>-0.908962</td>\n",
       "      <td>-0.429310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>-1.847858</td>\n",
       "      <td>-1.871812</td>\n",
       "      <td>-1.895765</td>\n",
       "      <td>-1.967346</td>\n",
       "      <td>-1.800114</td>\n",
       "      <td>-2.106233</td>\n",
       "      <td>-2.150306</td>\n",
       "      <td>-1.890654</td>\n",
       "      <td>-1.900783</td>\n",
       "      <td>-1.787081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808308</td>\n",
       "      <td>0.685451</td>\n",
       "      <td>1.086268</td>\n",
       "      <td>1.113614</td>\n",
       "      <td>0.917155</td>\n",
       "      <td>0.878332</td>\n",
       "      <td>1.082365</td>\n",
       "      <td>1.070563</td>\n",
       "      <td>0.825291</td>\n",
       "      <td>0.938181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>-0.128532</td>\n",
       "      <td>0.202311</td>\n",
       "      <td>0.533154</td>\n",
       "      <td>-0.095510</td>\n",
       "      <td>-0.531502</td>\n",
       "      <td>0.919737</td>\n",
       "      <td>1.139471</td>\n",
       "      <td>-0.459996</td>\n",
       "      <td>1.278264</td>\n",
       "      <td>1.857021</td>\n",
       "      <td>...</td>\n",
       "      <td>1.414573</td>\n",
       "      <td>-0.344542</td>\n",
       "      <td>-0.843103</td>\n",
       "      <td>0.051973</td>\n",
       "      <td>-0.293891</td>\n",
       "      <td>0.252092</td>\n",
       "      <td>0.500628</td>\n",
       "      <td>-0.260124</td>\n",
       "      <td>0.478282</td>\n",
       "      <td>-0.745278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "2250 -0.607318 -0.176849  0.253621  0.046283  0.363075 -0.908132 -1.057989   \n",
       "2388 -0.672346 -0.549175 -0.426003 -0.188362 -0.460143 -0.086277  0.810065   \n",
       "277  -0.360273  0.213458  0.787189  0.297611  1.292560  1.262779 -0.010575   \n",
       "308  -1.847858 -1.871812 -1.895765 -1.967346 -1.800114 -2.106233 -2.150306   \n",
       "2598 -0.128532  0.202311  0.533154 -0.095510 -0.531502  0.919737  1.139471   \n",
       "\n",
       "          7         8         9       ...         3187      3188      3189  \\\n",
       "2250  0.576840 -1.870078 -0.848080    ...    -0.094942 -2.865447  0.187692   \n",
       "2388  0.190190 -0.758031 -0.484242    ...    -0.227857 -0.370442 -1.295903   \n",
       "277  -0.145942 -0.829546 -1.702213    ...     0.623846 -0.265967 -0.290333   \n",
       "308  -1.890654 -1.900783 -1.787081    ...     0.808308  0.685451  1.086268   \n",
       "2598 -0.459996  1.278264  1.857021    ...     1.414573 -0.344542 -0.843103   \n",
       "\n",
       "          3190      3191      3192      3193      3194      3195      3196  \n",
       "2250 -1.064967 -0.248287 -1.223271  0.084114 -1.508292 -0.383636 -0.419630  \n",
       "2388 -0.782130  1.642813 -0.217147 -0.733932  0.615267  0.046936  0.254789  \n",
       "277   0.151415  0.398234  0.448771 -0.828644 -1.029438 -0.908962 -0.429310  \n",
       "308   1.113614  0.917155  0.878332  1.082365  1.070563  0.825291  0.938181  \n",
       "2598  0.051973 -0.293891  0.252092  0.500628 -0.260124  0.478282 -0.745278  \n",
       "\n",
       "[5 rows x 3197 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep ```c4_kep``` to be used as unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  make sure this is the right size, the right number of columns\n",
    "\n",
    "\n",
    "unseen_data = c4_holdout.iloc[:,2:3199]\n",
    "# unseen_data.drop(index=7713, inplace = True)\n",
    "# unseen_data.tail()\n",
    "\n",
    "# scale\n",
    "unseen_data = unseen_data.T\n",
    "\n",
    "scaled_unseen = ss.fit_transform(unseen_data)\n",
    "unseen_data = pd.DataFrame(scaled_unseen, columns=unseen_data.columns)\n",
    "\n",
    "unseen_data = unseen_data.T\n",
    "\n",
    "# unseen_data.head()\n",
    "\n",
    "# Change the shape\n",
    "array_unseen = np.array(unseen_data)\n",
    "array_unseen = np.expand_dims(array_unseen, axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things to tune over\n",
    "#     number of layers\n",
    "#     order of layers\n",
    "#     filters\n",
    "#     filter size\n",
    "#     nodes\n",
    "#     regularization\n",
    "# # Normalize outputs from previous layer.\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# # Leaky ReLU activation function.\n",
    "# model.add(LeakyReLU())\n",
    "\n",
    "# try changing the learning rate\n",
    "#     also the decay rate\n",
    "\n",
    "# Things to try with the data itself\n",
    "#     normalizing light data\n",
    "#     combining confirmed planets with a different dataset\n",
    "#     spline smoothing\n",
    "\n",
    "# try changing the size of the neurons\n",
    "#     meaning input dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into an array and then change the dimensions\n",
    "X_array = np.array(X_train)\n",
    "X_array = np.expand_dims(X_array, axis = 2)\n",
    "\n",
    "# do this for the test set too\n",
    "X_test_array = np.array(X_test)\n",
    "X_test_array = np.expand_dims(X_test_array, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional and layer.\n",
    "model.add(Conv1D(filters = 5, # tuned for 5\n",
    "                 kernel_size = (15),  # filter size, tuned for 15\n",
    "                 activation = 'relu',\n",
    "                 input_shape = (3197, 1))) # dimensions of training data\n",
    "# Pooling:\n",
    "model.add(MaxPooling1D(pool_size = (5))) # tuned for 5\n",
    "model.add(Dropout(0.1)) # regularization tuned for .1\n",
    "\n",
    "\n",
    "# Convolutional layer\n",
    "model.add(Conv1D(filters = 7, # tuned for 7\n",
    "                 kernel_size = 7, # tuned for 7\n",
    "                 activation = 'relu'))\n",
    "# Pooling layer.\n",
    "model.add(MaxPooling1D(pool_size = (7))) #tuned for 7\n",
    "model.add(Dropout(0.25)) # regularization tuned for .25\n",
    "\n",
    "# Convolutional layer\n",
    "model.add(Conv1D(filters = 10, # tuned to 10\n",
    "                 kernel_size = 10, # tuned to 10\n",
    "                 activation = 'relu'))\n",
    "# Pooling layer.\n",
    "model.add(MaxPooling1D(pool_size = (5))) # tuned to 5\n",
    "model.add(Dropout(0.5)) # regularization tuned to .5\n",
    "\n",
    "# In order to go from a convolutional/pooling layer, we have to organize our neurons.\n",
    "model.add(Flatten())\n",
    "\n",
    "# # Fully connected layers.\n",
    "model.add(Dense(2500, activation = 'relu'))\n",
    "model.add(Dropout(0.7)) # regularization tuned to .7\n",
    "\n",
    "model.add(Dense(1000, activation = 'relu'))\n",
    "model.add(Dropout(0.7)) # regularization tuned to .7\n",
    "\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# Changing adam optimization parameters\n",
    "optimizers.adam(lr = 0.001, decay = 0)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2910 samples, validate on 970 samples\n",
      "Epoch 1/200\n",
      "2910/2910 [==============================] - 41s 14ms/step - loss: 0.6912 - acc: 0.6595 - val_loss: 0.6364 - val_acc: 0.7062\n",
      "Epoch 2/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.6264 - acc: 0.6880 - val_loss: 0.6144 - val_acc: 0.6990\n",
      "Epoch 3/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.6166 - acc: 0.6962 - val_loss: 0.6113 - val_acc: 0.7031\n",
      "Epoch 4/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.6001 - acc: 0.7017 - val_loss: 0.5888 - val_acc: 0.7031\n",
      "Epoch 5/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.6037 - acc: 0.7048 - val_loss: 0.5864 - val_acc: 0.7062\n",
      "Epoch 6/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5970 - acc: 0.7052 - val_loss: 0.5808 - val_acc: 0.7062\n",
      "Epoch 7/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5960 - acc: 0.7058 - val_loss: 0.5816 - val_acc: 0.7113\n",
      "Epoch 8/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5881 - acc: 0.7124 - val_loss: 0.5752 - val_acc: 0.7144\n",
      "Epoch 9/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5850 - acc: 0.7103 - val_loss: 0.5735 - val_acc: 0.7134\n",
      "Epoch 10/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5820 - acc: 0.7134 - val_loss: 0.5620 - val_acc: 0.7155\n",
      "Epoch 11/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5814 - acc: 0.7069 - val_loss: 0.5650 - val_acc: 0.7155\n",
      "Epoch 12/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5763 - acc: 0.7131 - val_loss: 0.5737 - val_acc: 0.7134\n",
      "Epoch 13/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5649 - acc: 0.7199 - val_loss: 0.5801 - val_acc: 0.7134\n",
      "Epoch 14/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5657 - acc: 0.7251 - val_loss: 0.5516 - val_acc: 0.7216\n",
      "Epoch 15/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5675 - acc: 0.7275 - val_loss: 0.5605 - val_acc: 0.7175\n",
      "Epoch 16/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5484 - acc: 0.7330 - val_loss: 0.5811 - val_acc: 0.7196\n",
      "Epoch 17/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5558 - acc: 0.7309 - val_loss: 0.5453 - val_acc: 0.7237\n",
      "Epoch 18/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5557 - acc: 0.7399 - val_loss: 0.5473 - val_acc: 0.7268\n",
      "Epoch 19/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5451 - acc: 0.7426 - val_loss: 0.5394 - val_acc: 0.7351\n",
      "Epoch 20/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5336 - acc: 0.7368 - val_loss: 0.5670 - val_acc: 0.7258\n",
      "Epoch 21/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5397 - acc: 0.7433 - val_loss: 0.5170 - val_acc: 0.7402\n",
      "Epoch 22/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5342 - acc: 0.7540 - val_loss: 0.5030 - val_acc: 0.7526\n",
      "Epoch 23/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5349 - acc: 0.7433 - val_loss: 0.5315 - val_acc: 0.7433\n",
      "Epoch 24/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5352 - acc: 0.7426 - val_loss: 0.5273 - val_acc: 0.7381\n",
      "Epoch 25/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5345 - acc: 0.7495 - val_loss: 0.5119 - val_acc: 0.7495\n",
      "Epoch 26/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5280 - acc: 0.7577 - val_loss: 0.4976 - val_acc: 0.7485\n",
      "Epoch 27/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5133 - acc: 0.7715 - val_loss: 0.5038 - val_acc: 0.7577\n",
      "Epoch 28/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5147 - acc: 0.7629 - val_loss: 0.5334 - val_acc: 0.7412\n",
      "Epoch 29/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5139 - acc: 0.7608 - val_loss: 0.4933 - val_acc: 0.7649\n",
      "Epoch 30/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5025 - acc: 0.7842 - val_loss: 0.5028 - val_acc: 0.7577\n",
      "Epoch 31/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5101 - acc: 0.7680 - val_loss: 0.4940 - val_acc: 0.7577\n",
      "Epoch 32/200\n",
      "2910/2910 [==============================] - 10s 3ms/step - loss: 0.4911 - acc: 0.7777 - val_loss: 0.5206 - val_acc: 0.7608\n",
      "Epoch 33/200\n",
      "2910/2910 [==============================] - 10s 3ms/step - loss: 0.5044 - acc: 0.7694 - val_loss: 0.5025 - val_acc: 0.7598\n",
      "Epoch 34/200\n",
      "2910/2910 [==============================] - 10s 4ms/step - loss: 0.5010 - acc: 0.7718 - val_loss: 0.5177 - val_acc: 0.7577\n",
      "Epoch 35/200\n",
      "2910/2910 [==============================] - 10s 3ms/step - loss: 0.4965 - acc: 0.7718 - val_loss: 0.5265 - val_acc: 0.7557\n",
      "Epoch 36/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4810 - acc: 0.7749 - val_loss: 0.5001 - val_acc: 0.7701\n",
      "Epoch 37/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.5009 - acc: 0.7746 - val_loss: 0.4886 - val_acc: 0.7691\n",
      "Epoch 38/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4824 - acc: 0.7780 - val_loss: 0.4786 - val_acc: 0.7773\n",
      "Epoch 39/200\n",
      "2910/2910 [==============================] - 10s 3ms/step - loss: 0.4806 - acc: 0.7821 - val_loss: 0.4843 - val_acc: 0.7691\n",
      "Epoch 40/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4864 - acc: 0.7722 - val_loss: 0.5025 - val_acc: 0.7577\n",
      "Epoch 41/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4934 - acc: 0.7811 - val_loss: 0.4887 - val_acc: 0.7619\n",
      "Epoch 42/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4807 - acc: 0.7825 - val_loss: 0.5036 - val_acc: 0.7629\n",
      "Epoch 43/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4835 - acc: 0.7842 - val_loss: 0.4906 - val_acc: 0.7629\n",
      "Epoch 44/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4960 - acc: 0.7753 - val_loss: 0.4781 - val_acc: 0.7784\n",
      "Epoch 45/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4768 - acc: 0.8000 - val_loss: 0.4667 - val_acc: 0.7845\n",
      "Epoch 46/200\n",
      "2910/2910 [==============================] - 10s 3ms/step - loss: 0.4806 - acc: 0.7873 - val_loss: 0.4667 - val_acc: 0.7784\n",
      "Epoch 47/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4607 - acc: 0.7863 - val_loss: 0.4728 - val_acc: 0.7814\n",
      "Epoch 48/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4634 - acc: 0.7880 - val_loss: 0.4617 - val_acc: 0.7835\n",
      "Epoch 49/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4766 - acc: 0.7842 - val_loss: 0.4802 - val_acc: 0.7804\n",
      "Epoch 50/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4531 - acc: 0.8007 - val_loss: 0.4358 - val_acc: 0.7979\n",
      "Epoch 51/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4753 - acc: 0.7880 - val_loss: 0.4743 - val_acc: 0.7804\n",
      "Epoch 52/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4490 - acc: 0.7955 - val_loss: 0.4455 - val_acc: 0.7948\n",
      "Epoch 53/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4686 - acc: 0.7997 - val_loss: 0.4625 - val_acc: 0.7866\n",
      "Epoch 54/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4655 - acc: 0.7880 - val_loss: 0.4702 - val_acc: 0.7804\n",
      "Epoch 55/200\n",
      "2910/2910 [==============================] - 10s 3ms/step - loss: 0.4806 - acc: 0.7821 - val_loss: 0.4671 - val_acc: 0.7753\n",
      "Epoch 56/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4567 - acc: 0.7979 - val_loss: 0.4884 - val_acc: 0.7742\n",
      "Epoch 57/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4637 - acc: 0.8038 - val_loss: 0.4561 - val_acc: 0.7845\n",
      "Epoch 58/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4617 - acc: 0.7924 - val_loss: 0.4447 - val_acc: 0.7948\n",
      "Epoch 59/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4621 - acc: 0.7942 - val_loss: 0.4650 - val_acc: 0.7856\n",
      "Epoch 60/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4656 - acc: 0.7914 - val_loss: 0.4530 - val_acc: 0.7959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4607 - acc: 0.8010 - val_loss: 0.4450 - val_acc: 0.7948\n",
      "Epoch 62/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4407 - acc: 0.8055 - val_loss: 0.4660 - val_acc: 0.7856\n",
      "Epoch 63/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4534 - acc: 0.8041 - val_loss: 0.4707 - val_acc: 0.7845\n",
      "Epoch 64/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4544 - acc: 0.7997 - val_loss: 0.4677 - val_acc: 0.7897\n",
      "Epoch 65/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4506 - acc: 0.7990 - val_loss: 0.4438 - val_acc: 0.7938\n",
      "Epoch 66/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4502 - acc: 0.8062 - val_loss: 0.4602 - val_acc: 0.7856\n",
      "Epoch 67/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4517 - acc: 0.7924 - val_loss: 0.4973 - val_acc: 0.7742\n",
      "Epoch 68/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4482 - acc: 0.8021 - val_loss: 0.4429 - val_acc: 0.7918\n",
      "Epoch 69/200\n",
      "2910/2910 [==============================] - 10s 3ms/step - loss: 0.4517 - acc: 0.8014 - val_loss: 0.4634 - val_acc: 0.7856\n",
      "Epoch 70/200\n",
      "2910/2910 [==============================] - 11s 4ms/step - loss: 0.4599 - acc: 0.8052 - val_loss: 0.4720 - val_acc: 0.7866\n",
      "Epoch 71/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4552 - acc: 0.8137 - val_loss: 0.4350 - val_acc: 0.8000\n",
      "Epoch 72/200\n",
      "2910/2910 [==============================] - 10s 3ms/step - loss: 0.4380 - acc: 0.8027 - val_loss: 0.4482 - val_acc: 0.7959\n",
      "Epoch 73/200\n",
      "2910/2910 [==============================] - 10s 4ms/step - loss: 0.4524 - acc: 0.7959 - val_loss: 0.4584 - val_acc: 0.7897\n",
      "Epoch 74/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4405 - acc: 0.7986 - val_loss: 0.4562 - val_acc: 0.7938\n",
      "Epoch 75/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4362 - acc: 0.8038 - val_loss: 0.4566 - val_acc: 0.7938\n",
      "Epoch 76/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4281 - acc: 0.8117 - val_loss: 0.4605 - val_acc: 0.7938\n",
      "Epoch 77/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4281 - acc: 0.8127 - val_loss: 0.4397 - val_acc: 0.8052\n",
      "Epoch 78/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4366 - acc: 0.8072 - val_loss: 0.4358 - val_acc: 0.8031\n",
      "Epoch 79/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4334 - acc: 0.8168 - val_loss: 0.4509 - val_acc: 0.8000\n",
      "Epoch 80/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4385 - acc: 0.8072 - val_loss: 0.4317 - val_acc: 0.8175\n",
      "Epoch 81/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4272 - acc: 0.8110 - val_loss: 0.4537 - val_acc: 0.7938\n",
      "Epoch 82/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4332 - acc: 0.8124 - val_loss: 0.4322 - val_acc: 0.8103\n",
      "Epoch 83/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4347 - acc: 0.8131 - val_loss: 0.4616 - val_acc: 0.7928\n",
      "Epoch 84/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4227 - acc: 0.8144 - val_loss: 0.4541 - val_acc: 0.7959\n",
      "Epoch 85/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4364 - acc: 0.8175 - val_loss: 0.4282 - val_acc: 0.8186\n",
      "Epoch 86/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4193 - acc: 0.8182 - val_loss: 0.4366 - val_acc: 0.8165\n",
      "Epoch 87/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4257 - acc: 0.8168 - val_loss: 0.4588 - val_acc: 0.7948\n",
      "Epoch 88/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4204 - acc: 0.8182 - val_loss: 0.4347 - val_acc: 0.8155\n",
      "Epoch 89/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4381 - acc: 0.8162 - val_loss: 0.4504 - val_acc: 0.8041\n",
      "Epoch 90/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4304 - acc: 0.8148 - val_loss: 0.4388 - val_acc: 0.8103\n",
      "Epoch 91/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4162 - acc: 0.8210 - val_loss: 0.4324 - val_acc: 0.8165\n",
      "Epoch 92/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4153 - acc: 0.8230 - val_loss: 0.4428 - val_acc: 0.8134\n",
      "Epoch 93/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4147 - acc: 0.8162 - val_loss: 0.4193 - val_acc: 0.8299\n",
      "Epoch 94/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4256 - acc: 0.8113 - val_loss: 0.4566 - val_acc: 0.8082\n",
      "Epoch 95/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4249 - acc: 0.8206 - val_loss: 0.4310 - val_acc: 0.8144\n",
      "Epoch 96/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4216 - acc: 0.8206 - val_loss: 0.4695 - val_acc: 0.7990\n",
      "Epoch 97/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4248 - acc: 0.8192 - val_loss: 0.4640 - val_acc: 0.8010\n",
      "Epoch 98/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4196 - acc: 0.8131 - val_loss: 0.4539 - val_acc: 0.8031\n",
      "Epoch 99/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4069 - acc: 0.8203 - val_loss: 0.4272 - val_acc: 0.8206\n",
      "Epoch 100/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4118 - acc: 0.8285 - val_loss: 0.4661 - val_acc: 0.8031\n",
      "Epoch 101/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4308 - acc: 0.8131 - val_loss: 0.4286 - val_acc: 0.8155\n",
      "Epoch 102/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4106 - acc: 0.8289 - val_loss: 0.4157 - val_acc: 0.8278\n",
      "Epoch 103/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4121 - acc: 0.8268 - val_loss: 0.4448 - val_acc: 0.8113\n",
      "Epoch 104/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4232 - acc: 0.8216 - val_loss: 0.4380 - val_acc: 0.8155\n",
      "Epoch 105/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4093 - acc: 0.8227 - val_loss: 0.4478 - val_acc: 0.8021\n",
      "Epoch 106/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4178 - acc: 0.8216 - val_loss: 0.4224 - val_acc: 0.8216\n",
      "Epoch 107/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4072 - acc: 0.8265 - val_loss: 0.4591 - val_acc: 0.8041\n",
      "Epoch 108/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4115 - acc: 0.8192 - val_loss: 0.4516 - val_acc: 0.8021\n",
      "Epoch 109/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4198 - acc: 0.8230 - val_loss: 0.4402 - val_acc: 0.8082\n",
      "Epoch 110/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4144 - acc: 0.8206 - val_loss: 0.4131 - val_acc: 0.8278\n",
      "Epoch 111/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4109 - acc: 0.8278 - val_loss: 0.4710 - val_acc: 0.7969\n",
      "Epoch 112/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4045 - acc: 0.8234 - val_loss: 0.4640 - val_acc: 0.8021\n",
      "Epoch 113/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4061 - acc: 0.8271 - val_loss: 0.4491 - val_acc: 0.8134\n",
      "Epoch 114/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4263 - acc: 0.8096 - val_loss: 0.4395 - val_acc: 0.8124\n",
      "Epoch 115/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4062 - acc: 0.8237 - val_loss: 0.4294 - val_acc: 0.8237\n",
      "Epoch 116/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4042 - acc: 0.8261 - val_loss: 0.4380 - val_acc: 0.8155\n",
      "Epoch 117/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4086 - acc: 0.8271 - val_loss: 0.4274 - val_acc: 0.8247\n",
      "Epoch 118/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4092 - acc: 0.8275 - val_loss: 0.4468 - val_acc: 0.8175\n",
      "Epoch 119/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3977 - acc: 0.8227 - val_loss: 0.4279 - val_acc: 0.8206\n",
      "Epoch 120/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4060 - acc: 0.8216 - val_loss: 0.4191 - val_acc: 0.8278\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2910/2910 [==============================] - 8s 3ms/step - loss: 0.4012 - acc: 0.8326 - val_loss: 0.4091 - val_acc: 0.8361\n",
      "Epoch 122/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4104 - acc: 0.8247 - val_loss: 0.4286 - val_acc: 0.8206\n",
      "Epoch 123/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4193 - acc: 0.8213 - val_loss: 0.4313 - val_acc: 0.8196\n",
      "Epoch 124/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3953 - acc: 0.8316 - val_loss: 0.4646 - val_acc: 0.8103\n",
      "Epoch 125/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4035 - acc: 0.8306 - val_loss: 0.4070 - val_acc: 0.8320\n",
      "Epoch 126/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4079 - acc: 0.8247 - val_loss: 0.4510 - val_acc: 0.8155\n",
      "Epoch 127/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4023 - acc: 0.8282 - val_loss: 0.4315 - val_acc: 0.8196\n",
      "Epoch 128/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3906 - acc: 0.8309 - val_loss: 0.4286 - val_acc: 0.8278\n",
      "Epoch 129/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4104 - acc: 0.8247 - val_loss: 0.4409 - val_acc: 0.8165\n",
      "Epoch 130/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4055 - acc: 0.8241 - val_loss: 0.4354 - val_acc: 0.8206\n",
      "Epoch 131/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3972 - acc: 0.8313 - val_loss: 0.4527 - val_acc: 0.8155\n",
      "Epoch 132/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4036 - acc: 0.8268 - val_loss: 0.4169 - val_acc: 0.8278\n",
      "Epoch 133/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3954 - acc: 0.8371 - val_loss: 0.4393 - val_acc: 0.8155\n",
      "Epoch 134/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4063 - acc: 0.8241 - val_loss: 0.4126 - val_acc: 0.8330\n",
      "Epoch 135/200\n",
      "2910/2910 [==============================] - 11s 4ms/step - loss: 0.3793 - acc: 0.8426 - val_loss: 0.4326 - val_acc: 0.8196\n",
      "Epoch 136/200\n",
      "2910/2910 [==============================] - 14s 5ms/step - loss: 0.3945 - acc: 0.8299 - val_loss: 0.4032 - val_acc: 0.8371\n",
      "Epoch 137/200\n",
      "2910/2910 [==============================] - 10s 3ms/step - loss: 0.3932 - acc: 0.8313 - val_loss: 0.4016 - val_acc: 0.8340\n",
      "Epoch 138/200\n",
      "2910/2910 [==============================] - 11s 4ms/step - loss: 0.3934 - acc: 0.8316 - val_loss: 0.4360 - val_acc: 0.8206\n",
      "Epoch 139/200\n",
      "2910/2910 [==============================] - 10s 4ms/step - loss: 0.3852 - acc: 0.8354 - val_loss: 0.4392 - val_acc: 0.8196\n",
      "Epoch 140/200\n",
      "2910/2910 [==============================] - 11s 4ms/step - loss: 0.3956 - acc: 0.8309 - val_loss: 0.4406 - val_acc: 0.8144\n",
      "Epoch 141/200\n",
      "2910/2910 [==============================] - 10s 3ms/step - loss: 0.3949 - acc: 0.8320 - val_loss: 0.4075 - val_acc: 0.8340\n",
      "Epoch 142/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4034 - acc: 0.8282 - val_loss: 0.4510 - val_acc: 0.8186\n",
      "Epoch 143/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3899 - acc: 0.8289 - val_loss: 0.4267 - val_acc: 0.8258\n",
      "Epoch 144/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3964 - acc: 0.8330 - val_loss: 0.4119 - val_acc: 0.8289\n",
      "Epoch 145/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3717 - acc: 0.8388 - val_loss: 0.4361 - val_acc: 0.8237\n",
      "Epoch 146/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4028 - acc: 0.8296 - val_loss: 0.4360 - val_acc: 0.8206\n",
      "Epoch 147/200\n",
      "2910/2910 [==============================] - 10s 3ms/step - loss: 0.3941 - acc: 0.8320 - val_loss: 0.4103 - val_acc: 0.8351\n",
      "Epoch 148/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3841 - acc: 0.8388 - val_loss: 0.4419 - val_acc: 0.8196\n",
      "Epoch 149/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3977 - acc: 0.8368 - val_loss: 0.4165 - val_acc: 0.8371\n",
      "Epoch 150/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4047 - acc: 0.8278 - val_loss: 0.4339 - val_acc: 0.8227\n",
      "Epoch 151/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3933 - acc: 0.8357 - val_loss: 0.4613 - val_acc: 0.8144\n",
      "Epoch 152/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3880 - acc: 0.8316 - val_loss: 0.4200 - val_acc: 0.8320\n",
      "Epoch 153/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3931 - acc: 0.8347 - val_loss: 0.4191 - val_acc: 0.8351\n",
      "Epoch 154/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3979 - acc: 0.8313 - val_loss: 0.4246 - val_acc: 0.8320\n",
      "Epoch 155/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3877 - acc: 0.8488 - val_loss: 0.4254 - val_acc: 0.8175\n",
      "Epoch 156/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4003 - acc: 0.8344 - val_loss: 0.4247 - val_acc: 0.8237\n",
      "Epoch 157/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3851 - acc: 0.8375 - val_loss: 0.4283 - val_acc: 0.8186\n",
      "Epoch 158/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3840 - acc: 0.8351 - val_loss: 0.4524 - val_acc: 0.8093\n",
      "Epoch 159/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3767 - acc: 0.8464 - val_loss: 0.4143 - val_acc: 0.8278\n",
      "Epoch 160/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3850 - acc: 0.8330 - val_loss: 0.4352 - val_acc: 0.8144\n",
      "Epoch 161/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3840 - acc: 0.8351 - val_loss: 0.4544 - val_acc: 0.8124\n",
      "Epoch 162/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3941 - acc: 0.8368 - val_loss: 0.4168 - val_acc: 0.8309\n",
      "Epoch 163/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4097 - acc: 0.8361 - val_loss: 0.4530 - val_acc: 0.8113\n",
      "Epoch 164/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3896 - acc: 0.8368 - val_loss: 0.4006 - val_acc: 0.8443\n",
      "Epoch 165/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3852 - acc: 0.8337 - val_loss: 0.4263 - val_acc: 0.8247\n",
      "Epoch 166/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3794 - acc: 0.8385 - val_loss: 0.4243 - val_acc: 0.8289\n",
      "Epoch 167/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3743 - acc: 0.8340 - val_loss: 0.4525 - val_acc: 0.8237\n",
      "Epoch 168/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3785 - acc: 0.8361 - val_loss: 0.4203 - val_acc: 0.8309\n",
      "Epoch 169/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3890 - acc: 0.8333 - val_loss: 0.4133 - val_acc: 0.8299\n",
      "Epoch 170/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3726 - acc: 0.8495 - val_loss: 0.4301 - val_acc: 0.8381\n",
      "Epoch 171/200\n",
      "2910/2910 [==============================] - 10s 3ms/step - loss: 0.3773 - acc: 0.8371 - val_loss: 0.4102 - val_acc: 0.8340\n",
      "Epoch 172/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3921 - acc: 0.8326 - val_loss: 0.4270 - val_acc: 0.8289\n",
      "Epoch 173/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3888 - acc: 0.8361 - val_loss: 0.4194 - val_acc: 0.8299\n",
      "Epoch 174/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3983 - acc: 0.8375 - val_loss: 0.4288 - val_acc: 0.8216\n",
      "Epoch 175/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3780 - acc: 0.8474 - val_loss: 0.4313 - val_acc: 0.8351\n",
      "Epoch 176/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3914 - acc: 0.8409 - val_loss: 0.4306 - val_acc: 0.8309\n",
      "Epoch 177/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.4005 - acc: 0.8323 - val_loss: 0.4395 - val_acc: 0.8237\n",
      "Epoch 178/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3854 - acc: 0.8388 - val_loss: 0.4375 - val_acc: 0.8175\n",
      "Epoch 179/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3840 - acc: 0.8368 - val_loss: 0.4380 - val_acc: 0.8258\n",
      "Epoch 180/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3872 - acc: 0.8381 - val_loss: 0.4275 - val_acc: 0.8247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3956 - acc: 0.8330 - val_loss: 0.4279 - val_acc: 0.8247\n",
      "Epoch 182/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3804 - acc: 0.8423 - val_loss: 0.4249 - val_acc: 0.8278\n",
      "Epoch 183/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3862 - acc: 0.8368 - val_loss: 0.4414 - val_acc: 0.8237\n",
      "Epoch 184/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3768 - acc: 0.8361 - val_loss: 0.4496 - val_acc: 0.8206\n",
      "Epoch 185/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3795 - acc: 0.8385 - val_loss: 0.4527 - val_acc: 0.8144\n",
      "Epoch 186/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3926 - acc: 0.8364 - val_loss: 0.4569 - val_acc: 0.8155\n",
      "Epoch 187/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3932 - acc: 0.8412 - val_loss: 0.4396 - val_acc: 0.8247\n",
      "Epoch 188/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3813 - acc: 0.8375 - val_loss: 0.4378 - val_acc: 0.8216\n",
      "Epoch 189/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3778 - acc: 0.8368 - val_loss: 0.4471 - val_acc: 0.8278\n",
      "Epoch 190/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3611 - acc: 0.8485 - val_loss: 0.4179 - val_acc: 0.8423\n",
      "Epoch 191/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3771 - acc: 0.8381 - val_loss: 0.4105 - val_acc: 0.8340\n",
      "Epoch 192/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3772 - acc: 0.8436 - val_loss: 0.4425 - val_acc: 0.8165\n",
      "Epoch 193/200\n",
      "2910/2910 [==============================] - 10s 3ms/step - loss: 0.3771 - acc: 0.8423 - val_loss: 0.4380 - val_acc: 0.8258\n",
      "Epoch 194/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3747 - acc: 0.8443 - val_loss: 0.4283 - val_acc: 0.8289\n",
      "Epoch 195/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3832 - acc: 0.8430 - val_loss: 0.4644 - val_acc: 0.8155\n",
      "Epoch 196/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3770 - acc: 0.8351 - val_loss: 0.4482 - val_acc: 0.8216\n",
      "Epoch 197/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3840 - acc: 0.8416 - val_loss: 0.4314 - val_acc: 0.8247\n",
      "Epoch 198/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3575 - acc: 0.8533 - val_loss: 0.4356 - val_acc: 0.8258\n",
      "Epoch 199/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3741 - acc: 0.8385 - val_loss: 0.4418 - val_acc: 0.8237\n",
      "Epoch 200/200\n",
      "2910/2910 [==============================] - 9s 3ms/step - loss: 0.3928 - acc: 0.8333 - val_loss: 0.4567 - val_acc: 0.8165\n"
     ]
    }
   ],
   "source": [
    "# best so far, .855 at ~100 epochs\n",
    "# 15 times better than chance at 50 epochs, .78 acc, also at 100 epochs .81\n",
    "# 12 times better than chance at 150 epochs , .86 accuracy\n",
    "result = model.fit(X_array,\n",
    "                    y_train,\n",
    "                    batch_size = 64,\n",
    "                    epochs = 150,\n",
    "                    verbose = 0,\n",
    "                   validation_data = (X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss over time.\n",
    "plt.figure()\n",
    "plt.plot(result.history['acc'])\n",
    "plt.plot(result.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='best')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on Unseen Data:\n",
    "Now that the model has been fit, lets see if we can use it to detect some planets in data not seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba or classification\n",
    "#     both, so we know what the model thinks and how confident it is\n",
    "y_unseen = model.predict_classes(array_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013 % Predicted to have planets\n",
      "0    4934\n",
      "1      66\n",
      "Name: prediction, dtype: int64\n",
      "0.008 % actually have planets\n",
      "0    4958\n",
      "1      42\n",
      "Name: LABEL, dtype: int64\n",
      "8  True positive planet stars predicted  12.12 % of all predictions 14.43  times better than chance\n",
      "58  False postives 87.88 % of all predicted\n"
     ]
    }
   ],
   "source": [
    "# make predictions df\n",
    "yhat_unseen = pd.DataFrame(y_unseen, columns=['prediction'])\n",
    "\n",
    "# make df of true labels and index\n",
    "true_y_unseen = c4_holdout['LABEL']\n",
    "true_y_unseen_df = pd.DataFrame(true_y_unseen)#, columns=['true'])\n",
    "true_y_unseen_df.reset_index(inplace=True)\n",
    "\n",
    "compare_df = pd.concat((true_y_unseen_df, yhat_unseen), axis=1)#, join = 'outer')\n",
    "\n",
    "# print out prediction rate and value_counts\n",
    "val_counts = yhat_unseen['prediction'].value_counts()\n",
    "print(round(val_counts[1]/val_counts.sum(), 3), '% Predicted to have planets')\n",
    "print(val_counts)\n",
    "\n",
    "# print out true rate and value_counts\n",
    "val_counts2 = true_y_unseen.value_counts()\n",
    "print(round(val_counts2[1]/val_counts2.sum(), 3), '% actually have planets')\n",
    "print(val_counts2)\n",
    "\n",
    "true_masked = compare_df[compare_df['LABEL'] == 1]\n",
    "fp = val_counts[1] - true_masked['prediction'].sum()\n",
    "tp = true_masked['prediction'].sum()\n",
    "\n",
    "# compare predictions to true\n",
    "\n",
    "print(tp, ' True positive planet stars predicted ',\n",
    "      round((tp/val_counts[1])*100, 2), '% of all predictions',\n",
    "     round((tp/val_counts[1])/(val_counts2[1]/val_counts2.sum()), 2), ' times better than chance')\n",
    "print(fp, ' False postives', round((fp / val_counts[1])*100, 2), '% of all predicted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### confusion matrix:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  True planet systems predicted  16.7 % of true\n"
     ]
    }
   ],
   "source": [
    "# compare predictions to true\n",
    "# yhat_unseen['true'] = true_y_unseen\n",
    "true_masked = compare_df[compare_df['LABEL'] == 1]\n",
    "print(true_masked['prediction'].sum(), ' True planet systems predicted ',\n",
    "      round(true_masked['prediction'].sum()/len(true_masked),3)*100, '% of true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the unseen data\n",
    "x_axis = list(range(unseen_data.shape[1]-2))\n",
    "plt.scatter(x_axis, unseen_data.iloc[4028, 2:])\n",
    "# plt.ylim(-2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of a Transit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_axis = list(range(join_planets.shape[1]-2))\n",
    "plt.scatter(x_axis, join_planets.iloc[23, 2:])\n",
    "# plt.ylim(10040, 10090)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Flux Level')\n",
    "plt.title('Possible Solar Flare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate model on test data\n",
    "# score = model.evaluate(X_test_array, y_test, verbose = 1)\n",
    "# labels = model.metrics_names\n",
    "\n",
    "# score\n",
    "# # labels\n",
    "# # model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # What is the best way to do this?\n",
    "# undersample?\n",
    "# oversample?\n",
    "# What is the best ratio?\n",
    "# will this affect my result/ my false positive rate?\n",
    "\n",
    "# change columns of kep3 so you can join it with the planet data\n",
    "#     make sure there are no gaps in the confirmed planets data\n",
    "#     or the other data\n",
    "#     cut down dfs to be the right size\n",
    "#     do I want to remove the confimed planets already in the kep3 set in case they are repeats?\n",
    "\n",
    "# is it possible that some of the planets don't pass in front of their stars for the 66 days I'm looking at?\n",
    "#     what proportion of exoplanets have orbits of less than 66 days?\n",
    "\n",
    "# how am I going to deal with the nulls?\n",
    "#     skip to the next nearest non-null value?\n",
    "#     how many nulls in a row are there?\n",
    "#     if this happens to almost all confirmed planets, its possible that the network may learn to find these \"skips\"\n",
    "#         should I then just drop any rows with too many consecutive nans? \n",
    "#         Pretty much every one has a string of at least 40 consecutive nans\n",
    "#     mean imputation may have a logical case here\n",
    "#         it would make sense that the level of light is between previous value and the next one + random noise\n",
    "#         what about for longer strings of missing values \n",
    "#         mean imputation could be good for avoiding creating false signals because of its smoothing effect\n",
    "#         the disadvantages of mean imputation may not be important because I am basically using neural networks for pattern detection\n",
    "#     maybe if it is a long string of missing values you want to skip to the next real data, \n",
    "#         mark if that had happened so I could tell if it contributes to false positives\n",
    "#     drop rows with more than 150 nulls? there are only 8\n",
    "#         1134    666\n",
    "#         752     408\n",
    "#         851     408\n",
    "#         1105    408\n",
    "#         441     408\n",
    "#         832     285\n",
    "#         871     230\n",
    "#         762     230\n",
    "\n",
    "# definitely get data on whether it is a binary star system or not\n",
    "#     how to feed these single features to the neural networks to help with pattern detection?\n",
    "\n",
    "# normalize the light curves\n",
    "\n",
    "# print out confusion matrix and other classification metrics\n",
    "\n",
    "# turn it into a gridsearch\n",
    "#     have it save the results to be analyzed later\n",
    "#     can I have it tune over generalizability to the unseen set?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
