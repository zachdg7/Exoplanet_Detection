{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_planets = pd.read_csv('../clean_planet_data/clean_labeled_planets.csv')\n",
    "\n",
    "c4_kep = pd.read_csv('../clean_planet_data/clean_kep_c4.csv')\n",
    "\n",
    "all_confirmed = pd.read_csv('../clean_planet_data/all_planets_list.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sure there are transits in the confirmed planets set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove last line from c4_kep because it has too many nulls:\n",
    "c4_kep.drop(index=7713, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign what used to be exposure to 0 because we're about to change that variable\n",
    "c4_kep['1'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "KIC 10000941  found @ index:  174 orbital period:  3.5047±0.0000\n",
      "250\n",
      "KIC 10002866  found @ index:  265 orbital period:  3.9370±0.0000\n",
      "KIC 10002866  found @ index:  265 orbital period:  28.0819±0.0001\n",
      "KIC 10002866  found @ index:  265 orbital period:  10.0888±0.0000\n",
      "KIC 10004519  found @ index:  328 orbital period:  9.8032±0.0000\n",
      "KIC 10004738  found @ index:  338 orbital period:  56.4754±0.0002\n",
      "KIC 10004738  found @ index:  338 orbital period:  92.8761±0.0008\n",
      "KIC 10004738  found @ index:  338 orbital period:  13.9307±0.0001\n",
      "KIC 10005788  found @ index:  398 orbital period:  10.9947±0.0000\n",
      "KIC 10006581  found @ index:  430 orbital period:  40.1100±0.0002\n",
      "500\n",
      "KIC 10010440  found @ index:  502 orbital period:  53.5991±0.0004\n",
      "KIC 10018233  found @ index:  691 orbital period:  16.2960±0.0001\n",
      "KIC 10019065  found @ index:  744 orbital period:  52.6298±0.0003\n",
      "750\n",
      "KIC 10019643  found @ index:  771 orbital period:  21.3473±0.0001\n",
      "KIC 10019643  found @ index:  771 orbital period:  7.8109±0.0001\n",
      "KIC 10019708  found @ index:  777 orbital period:  3.2687±0.0000\n",
      "KIC 10022908  found @ index:  821 orbital period:  6.9913±0.0000\n",
      "KIC 10024051  found @ index:  872 orbital period:  0.5774±0.0000\n",
      "KIC 10024701  found @ index:  905 orbital period:  14.3751±0.0000\n",
      "KIC 10024862  found @ index:  913 on 2nd level of loop orbital period:  567.04±0.03\n",
      "KIC 10026502  found @ index:  986 orbital period:  101.9518±0.0016\n",
      "1000\n",
      "KIC 10027247  found @ index:  1028 orbital period:  86.8290±0.0011\n",
      "KIC 10027323  found @ index:  1032 orbital period:  5.9237±0.0000\n",
      "KIC 10027323  found @ index:  1032 orbital period:  105.3564±0.0009\n",
      "KIC 10028535  found @ index:  1091 orbital period:  0.6631±0.0000\n",
      "KIC 10028792  found @ index:  1099 orbital period:  114.7309±0.0005\n",
      "KIC 10028792  found @ index:  1099 orbital period:  192.36±0.07\n",
      "1250\n",
      "KIC 10055126  found @ index:  1352 orbital period:  9.1761±0.0001\n",
      "KIC 10055126  found @ index:  1352 orbital period:  19.7383±0.0002\n",
      "KIC 10057494  found @ index:  1426 orbital period:  2.4181±0.0000\n",
      "KIC 10059645  found @ index:  1493 orbital period:  6.4944±0.0000\n",
      "1500\n",
      "KIC 10063208  found @ index:  1525 orbital period:  9.3281±0.0001\n",
      "KIC 10063802  found @ index:  1553 orbital period:  120.0181±0.0004\n",
      "1750\n",
      "KIC 10068659  found @ index:  1779 orbital period:  11.4769±0.0001\n",
      "KIC 10070468  found @ index:  1850 orbital period:  1.6819±0.0000\n",
      "2000\n",
      "KIC 10080248  found @ index:  2052 orbital period:  14.8783±0.0001\n",
      "2250\n",
      "KIC 10089911  found @ index:  2406 orbital period:  6.9671±0.0000\n",
      "2500\n",
      "KIC 10098844  found @ index:  2724 orbital period:  47.4500±0.0008\n",
      "2750\n",
      "KIC 10122255  found @ index:  2860 orbital period:  27.6655±0.0001\n",
      "KIC 10123064  found @ index:  2890 orbital period:  4.2437±0.0000\n",
      "3000\n",
      "KIC 10130039  found @ index:  3037 orbital period:  12.7580±0.0001\n",
      "KIC 10130039  found @ index:  3037 orbital period:  5.4703±0.0000\n",
      "KIC 10130039  found @ index:  3037 orbital period:  25.0985±0.0001\n",
      "KIC 10132832  found @ index:  3129 orbital period:  16.0768±0.0001\n",
      "3250\n",
      "KIC 10136549  found @ index:  3262 orbital period:  9.6932±0.0000\n",
      "KIC 10136549  found @ index:  3262 orbital period:  3.2928±0.0000\n",
      "KIC 10141900  found @ index:  3410 orbital period:  1.1966±0.0000\n",
      "3500\n",
      "KIC 10153855  found @ index:  3677 orbital period:  1.0638±0.0000\n",
      "KIC 10154388  found @ index:  3707 orbital period:  12.0622±0.0000\n",
      "3750\n",
      "KIC 10157458  found @ index:  3864 orbital period:  7.3368±0.0000\n",
      "KIC 10158729  found @ index:  3926 orbital period:  58.6018±0.0006\n",
      "4000\n",
      "KIC 10166274  found @ index:  4124 orbital period:  3.3537±0.0000\n",
      "KIC 10166274  found @ index:  4124 orbital period:  6.8774±0.0000\n",
      "KIC 10166274  found @ index:  4124 orbital period:  28.4645±0.0002\n",
      "KIC 10187017  found @ index:  4200 orbital period:  16.15\n",
      "KIC 10187017  found @ index:  4200 orbital period:  10.31\n",
      "KIC 10187017  found @ index:  4200 orbital period:  27.5\n",
      "KIC 10187017  found @ index:  4200 orbital period:  7.07\n",
      "KIC 10187017  found @ index:  4200 orbital period:  5.29\n",
      "KIC 10187159  found @ index:  4206 orbital period:  7.9643±0.0000\n",
      "4250\n",
      "KIC 10189546  found @ index:  4304 orbital period:  42.9496±0.0002\n",
      "KIC 10189546  found @ index:  4304 orbital period:  117.0405±0.0018\n",
      "KIC 10190777  found @ index:  4342 orbital period:  1.4112±0.0000\n",
      "4500\n",
      "KIC 10203349  found @ index:  4726 orbital period:  17.1465±0.0001\n",
      "4750\n",
      "KIC 10212441  found @ index:  4862 orbital period:  15.0447±0.0001\n",
      "KIC 10213902  found @ index:  4917 orbital period:  59.6225±0.0003\n",
      "KIC 10214162  found @ index:  4936 orbital period:  17.4240±0.0001\n",
      "5000\n",
      "5250\n",
      "5500\n",
      "KIC 10253547  found @ index:  5557 orbital period:  59.9806±0.0009\n",
      "KIC 10253547  found @ index:  5557 orbital period:  25.7457±0.0005\n",
      "5750\n",
      "KIC 10264660  found @ index:  5896 orbital period:  6.79\n",
      "KIC 10265898  found @ index:  5941 orbital period:  1.2603±0.0000\n",
      "KIC 10266615  found @ index:  5968 orbital period:  10.9403±0.0000\n",
      "6000\n",
      "KIC 10271806  found @ index:  6068 orbital period:  5.9250±0.0000\n",
      "KIC 10271806  found @ index:  6068 orbital period:  11.3494±0.0000\n",
      "KIC 10271806  found @ index:  6068 orbital period:  3.1329±0.0000\n",
      "KIC 10271806  found @ index:  6068 orbital period:  18.6436±0.0001\n",
      "KIC 10272442  found @ index:  6086 orbital period:  24.5435±0.0001\n",
      "KIC 10272640  found @ index:  6092 orbital period:  3.7706±0.0000\n",
      "6250\n",
      "KIC 10285631  found @ index:  6412 orbital period:  18.6840±0.0001\n",
      "6500\n",
      "KIC 10289119  found @ index:  6584 orbital period:  16.1047±0.0001\n",
      "KIC 10290666  found @ index:  6649 orbital period:  5.4585±0.0000\n",
      "6750\n",
      "KIC 10318874  found @ index:  6892 orbital period:  2.51\n",
      "KIC 10318874  found @ index:  6892 orbital period:  820±3\n",
      "7000\n",
      "KIC 10328393  found @ index:  7125 orbital period:  7.6263±0.0000\n",
      "KIC 10328393  found @ index:  7125 orbital period:  15.9956±0.0001\n",
      "KIC 10328393  found @ index:  7125 orbital period:  34.2115±0.0003\n",
      "KIC 10328458  found @ index:  7131 orbital period:  2.3523±0.0000\n",
      "KIC 10329196  found @ index:  7167 orbital period:  85.7565±0.0006\n",
      "KIC 10329469  found @ index:  7180 orbital period:  55.8227±0.0004\n",
      "KIC 10329835  found @ index:  7192 orbital period:  1.5237±0.0000\n",
      "KIC 10330115  found @ index:  7204 orbital period:  13.2141±0.0000\n",
      "7250\n",
      "KIC 10332883  found @ index:  7329 orbital period:  1.1512±0.0000\n",
      "KIC 10337258  found @ index:  7411 orbital period:  13.2854±0.0000\n",
      "KIC 10337517  found @ index:  7423 orbital period:  4.2926±0.0000\n",
      "7500\n",
      "KIC 10340423  found @ index:  7526 orbital period:  18.7942±0.0001\n",
      "KIC 10340423  found @ index:  7526 orbital period:  6.7390±0.0000\n",
      "KIC 10350571  found @ index:  7697 orbital period:  31.5923±0.0007\n"
     ]
    }
   ],
   "source": [
    "# Assign labels to c4_kep\n",
    "not_found = 0\n",
    "stars_to_drop = []\n",
    "\n",
    "for j in range(len(c4_kep)): # for every light curve from has_planets\n",
    "    if j % 250 == 0:\n",
    "        print(j)\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(all_confirmed)): # look through each star name in the list of all confirmed planets\n",
    "        try:\n",
    "            if all_confirmed.loc[i, 'Alternative star names'].find(c4_kep.iloc[j, 0]) != -1:\n",
    "                count += 1\n",
    "                print(c4_kep.iloc[j, 0], ' found @ index: ', j, 'orbital period: ', all_confirmed.loc[i, 'Orbital period [days]'])\n",
    "                c4_kep.loc[j, '1'] = 1\n",
    "    \n",
    "        except AttributeError: # if the alternate star names value are null\n",
    "            try:\n",
    "                if all_confirmed.loc[i, 'Star name'].find(c4_kep.iloc[j, 0]) != -1:\n",
    "                    count += 1\n",
    "                    print(c4_kep.iloc[j, 0], ' found @ index: ', j, 'on 2nd level of loop', 'orbital period: ', all_confirmed.loc[i, 'Orbital period [days]'])\n",
    "                    c4_kep.loc[j, '1'] = 1\n",
    "                    \n",
    "            except AttributeError: # if this is null too, keep going\n",
    "                continue\n",
    "    if count == 0:\n",
    "        not_found += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7642\n",
       "1      71\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c4_kep['1'].value_counts() # I counted only 6 stars with no planets with an orbit under 66 days in this set \n",
    "# indexes: 913, 986, 1028, 1099, 1553, 7167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4_kep.drop(index = [913, 986, 1028, 1099, 1553, 7167], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4_kep.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7707, 4158)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c4_kep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Preprocessing Data:\n",
    "### Mix confirmed planets into data so the model can learn what they are like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cut out the extra data to compare across the same timeline (~3200 points)\n",
    "join_planets = has_planets.iloc[:,:3199]\n",
    "\n",
    "# split c4_kep to add to training data\n",
    "to_train_on = c4_kep.head(2705).iloc[:,:3199]\n",
    "\n",
    "# set aside the last 5000 stars as a holdout set\n",
    "c4_holdout = c4_kep.tail(5000).iloc[:,:3199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_planets = join_planets.head(1129) # there are null rows at the bottom of this df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "master_df = pd.concat([join_planets, to_train_on], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Acc:  0.30073030777256127\n",
      "0.0    2681\n",
      "1.0    1153\n",
      "Name: 1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate Baseline Accuracy\n",
    "val_count = master_df['1'].value_counts()\n",
    "base_acc = val_count[1] / val_count.sum()\n",
    "\n",
    "print('Baseline Acc: ', base_acc)\n",
    "print(val_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "Normalize the light curves so that stars of different brightnesses can be compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make X and y\n",
    "X = master_df.iloc[:, 2:]\n",
    "y = master_df['1']\n",
    "\n",
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate StandardScaler as ss\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose to scale each lightcurve row (rather than columns)\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "\n",
    "# Scaling\n",
    "scaled_df = ss.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(scaled_df, columns=X_train.columns)\n",
    "\n",
    "test_scaled_df = ss.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(test_scaled_df, columns=X_test.columns)\n",
    "\n",
    "# Transpose back to normal\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into an array and then change the dimensions\n",
    "X_array = np.array(X_train)\n",
    "X_array = np.expand_dims(X_array, axis = 2)\n",
    "\n",
    "# do this for the test set too\n",
    "X_test_array = np.array(X_test)\n",
    "X_test_array = np.expand_dims(X_test_array, axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Unseen Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice out the light curve\n",
    "unseen_data = c4_holdout.iloc[:,2:3199]\n",
    "\n",
    "# Scale\n",
    "unseen_data = unseen_data.T # transpose to scale each lightcurve row (rather than columns)\n",
    "\n",
    "scaled_unseen = ss.fit_transform(unseen_data)\n",
    "unseen_data = pd.DataFrame(scaled_unseen, columns=unseen_data.columns)\n",
    "\n",
    "unseen_data = unseen_data.T # Transpose back to normal\n",
    "\n",
    "# Change the dimensions so it can be put through the neural network\n",
    "array_unseen = np.array(unseen_data)\n",
    "array_unseen = np.expand_dims(array_unseen, axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Define Functions for Evaluating the Results Later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be used later to show how the model learned over the epochs\n",
    "\n",
    "def learning_plots(title, metric, val_metric, y_label, c_train='#1f77b4', c_test='orange'):\n",
    "\n",
    "    # Instantiate plot\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot metric of interest\n",
    "    plt.plot(result.history[metric], color = c_train)\n",
    "    plt.plot(result.history[val_metric], color = c_test)\n",
    "\n",
    "    # Set title\n",
    "    plt.title(title)\n",
    "\n",
    "    # Set axis labels\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlabel('Epoch (# of iterations)')\n",
    "\n",
    "    # Add a legend\n",
    "    plt.legend(['Train', 'Test'], loc='best')\n",
    "\n",
    "    # Plot girdlines:\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be used for showing the evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(predictions, y_test): #, all_results):\n",
    "\n",
    "\n",
    "    # Calculate \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "    total = (tp + tn + fp + fn)\n",
    "\n",
    "    \n",
    "    index_labels = ['Accuracy', 'Sensitivity', 'Specificity', 'Precision']\n",
    "    scores = pd.DataFrame(index = index_labels, columns=['Results'])\n",
    "    \n",
    "# Calculate results\n",
    "    decimals = 3\n",
    "\n",
    "    scores.loc['Accuracy'] = round((tp+tn) / (total), decimals)\n",
    "    scores.loc['Sensitivity'] = round(tp / (tp+fn), decimals)\n",
    "    scores.loc['Specificity'] = round(tn / (tn+fp), decimals)\n",
    "    scores.loc['Precision'] = round(tp / (tp+fp), decimals)\n",
    "\n",
    "    # Display the rounded results\n",
    "    display(scores)\n",
    "    \n",
    "# Calculate values for the confusion matrix\n",
    "\n",
    "    confusion = pd.DataFrame(index= ['Pred. Positive','Pred. Negative', 'Total'])\n",
    "\n",
    "    confusion['Act. Positive'] = tp, fn, (tp + fn)\n",
    "    confusion['Act. Negative'] = fp, tn, (fp + tn)\n",
    "\n",
    "    confusion['Total'] = (tp + fp), (fn + tn), total\n",
    "\n",
    "    display(confusion)\n",
    "    \n",
    "    print((tp + fp), 'predicted to have planets', '\\n',\n",
    "    tp, 'true positive planet stars predicted', '\\n',\n",
    "    round(tp/(tp+fn)*100, 3), '% of all true planets', '\\n') \n",
    "    \n",
    "    # Rate of planets in predictions\n",
    "    tp_rate = (tp / (tp + fp))\n",
    "    # Rate of planets in all unseen test set\n",
    "    all_rate = (tp + fn) / total\n",
    "    \n",
    "    print(round(tp_rate / all_rate, 3), 'times better than chance')\n",
    "    \n",
    "    # False positive rate\n",
    "    print(round(fp/(tp+fp)*100, 3), '% false positive rate')\n",
    "    \n",
    "    return scores, confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be used to plot the auc-roc curve when evaluating the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_roc(y_test, y_hat_proba):\n",
    "# Plot ROC-AUC curve\n",
    "\n",
    "    # Generate False positive rate and True positive rate\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_hat_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot settings\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    line_width = 4\n",
    "    \n",
    "    # Title and labels\n",
    "    plt.title('ROC Curve', fontsize=25, position = (0.2,1))\n",
    "    plt.ylabel('TPR')\n",
    "    plt.xlabel('FPR')\n",
    "    \n",
    "    # Gridlines\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.plot(fpr, tpr, lw = line_width)\n",
    "    plt.plot([0, 1], [0,1], lw = line_width, linestyle = '--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Modeling:\n",
    "### Nueral Network Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Tune further:\n",
    "#     Pooling layers between all convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional and layer.\n",
    "model.add(Conv1D(filters = 15, # tuned for 5, 15 second round\n",
    "                 kernel_size = (20),  # filter size, tuned for 15, 20 second round\n",
    "                 activation = 'relu',\n",
    "                 input_shape = (3197, 1))) # dimensions of training data\n",
    "\n",
    "# Convolutional layer\n",
    "model.add(Conv1D(filters = 20,\n",
    "                 kernel_size = 30, # best so far 30\n",
    "                 activation = 'relu'))\n",
    "\n",
    "# Convolutional layer\n",
    "model.add(Conv1D(filters = 15,\n",
    "                 kernel_size = 60, # best so far 60\n",
    "                 activation = 'relu'))\n",
    "\n",
    "\n",
    "# Pooling:\n",
    "model.add(MaxPooling1D(pool_size = (3))) # best so far 3\n",
    "model.add(Dropout(0.2)) # best so far .2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Convolutional layer\n",
    "# model.add(Conv1D(filters = 7,\n",
    "#                  kernel_size = 20,\n",
    "#                  activation = 'relu'))\n",
    "# # # Pooling layer.\n",
    "# model.add(MaxPooling1D(pool_size = (5)))\n",
    "# # model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convolutional layer\n",
    "model.add(Conv1D(filters = 7, # tuned for 7, confirmed second round\n",
    "                 kernel_size = 20, # tuned for 7, 20 second round\n",
    "                 activation = 'relu'))\n",
    "# Pooling layer.\n",
    "model.add(MaxPooling1D(pool_size = (5))) #tuned for 7, 5 second round\n",
    "model.add(Dropout(0.25)) # regularization tuned for .25, confirmed 2nd round\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Convolutional layer\n",
    "# model.add(Conv1D(filters = 7,\n",
    "#                  kernel_size = 20,\n",
    "#                  activation = 'relu'))\n",
    "\n",
    "# Convolutional layer\n",
    "model.add(Conv1D(filters = 10, # tuned to 10, confirmed 2nd round\n",
    "                 kernel_size = 30, # tuned to 10, second round ~30\n",
    "                 activation = 'relu'))\n",
    "# Pooling layer.\n",
    "model.add(MaxPooling1D(pool_size = (5))) # tuned to 5, confirmed 2nd round\n",
    "model.add(Dropout(0.5)) # regularization tuned to .5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Organize neurons by flattening.\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected hidden layers.\n",
    "\n",
    "# Hidden layer 1\n",
    "model.add(Dense(2500, activation = 'relu')) # 1st round- 2500, .7 drop\n",
    "model.add(Dropout(0.4)) # best so far .4\n",
    "\n",
    "model.add(Dense(1500, activation = 'relu')), # 1st round- 1000, .7 drop, 2nd best so far 1500, .4 drop\n",
    "model.add(Dropout(0.5)) # best so far .5?\n",
    "\n",
    "# model.add(Dense(500, activation = 'relu'))\n",
    "\n",
    "\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# Setting learning rate and decay\n",
    "learn_rate = 0.001\n",
    "# # x% reduction in learing_rate by epoch: coef_by_epoch\n",
    "# coef_reduce = .75\n",
    "# coef_by_epoch = 30\n",
    "\n",
    "# Calculate decay\n",
    "decay = 0 #(learn_rate - (coef_reduce * learn_rate)) / coef_by_epoch\n",
    "\n",
    "# Changing adam optimization parameters\n",
    "optimizers.adam(lr = learn_rate, decay = decay)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2875 samples, validate on 959 samples\n",
      "Epoch 1/40\n",
      "2875/2875 [==============================] - 163s 57ms/step - loss: 0.6103 - acc: 0.6908 - val_loss: 0.6106 - val_acc: 0.6997\n",
      "Epoch 2/40\n",
      "2875/2875 [==============================] - 121s 42ms/step - loss: 0.5982 - acc: 0.6991 - val_loss: 0.6175 - val_acc: 0.6997\n",
      "Epoch 3/40\n",
      "2875/2875 [==============================] - 123s 43ms/step - loss: 0.5881 - acc: 0.6991 - val_loss: 0.5968 - val_acc: 0.7007\n",
      "Epoch 4/40\n",
      "2875/2875 [==============================] - 130s 45ms/step - loss: 0.5793 - acc: 0.6984 - val_loss: 0.5414 - val_acc: 0.7018\n",
      "Epoch 5/40\n",
      "2875/2875 [==============================] - 128s 45ms/step - loss: 0.5736 - acc: 0.7110 - val_loss: 0.5487 - val_acc: 0.7278\n",
      "Epoch 6/40\n",
      "2875/2875 [==============================] - 122s 43ms/step - loss: 0.5523 - acc: 0.7287 - val_loss: 0.5331 - val_acc: 0.7581\n",
      "Epoch 7/40\n",
      "2875/2875 [==============================] - 122s 42ms/step - loss: 0.5418 - acc: 0.7457 - val_loss: 0.5126 - val_acc: 0.7487\n",
      "Epoch 8/40\n",
      "2875/2875 [==============================] - 127s 44ms/step - loss: 0.5246 - acc: 0.7579 - val_loss: 0.4706 - val_acc: 0.7873\n",
      "Epoch 9/40\n",
      "2875/2875 [==============================] - 133s 46ms/step - loss: 0.5066 - acc: 0.7617 - val_loss: 0.4816 - val_acc: 0.7727\n",
      "Epoch 10/40\n",
      "2875/2875 [==============================] - 138s 48ms/step - loss: 0.5073 - acc: 0.7621 - val_loss: 0.4784 - val_acc: 0.7737\n",
      "Epoch 11/40\n",
      "2875/2875 [==============================] - 133s 46ms/step - loss: 0.4854 - acc: 0.7823 - val_loss: 0.4431 - val_acc: 0.7998\n",
      "Epoch 12/40\n",
      "2875/2875 [==============================] - 136s 47ms/step - loss: 0.4843 - acc: 0.7830 - val_loss: 0.4573 - val_acc: 0.7935\n",
      "Epoch 13/40\n",
      "2875/2875 [==============================] - 130s 45ms/step - loss: 0.4594 - acc: 0.7927 - val_loss: 0.4242 - val_acc: 0.8227\n",
      "Epoch 14/40\n",
      "2875/2875 [==============================] - 128s 45ms/step - loss: 0.4499 - acc: 0.8000 - val_loss: 0.4291 - val_acc: 0.8321\n",
      "Epoch 15/40\n",
      "2875/2875 [==============================] - 123s 43ms/step - loss: 0.4278 - acc: 0.8170 - val_loss: 0.3991 - val_acc: 0.8332\n",
      "Epoch 16/40\n",
      "2875/2875 [==============================] - 118s 41ms/step - loss: 0.4156 - acc: 0.8285 - val_loss: 0.3740 - val_acc: 0.8457\n",
      "Epoch 17/40\n",
      "2875/2875 [==============================] - 123s 43ms/step - loss: 0.3934 - acc: 0.8351 - val_loss: 0.4281 - val_acc: 0.8332\n",
      "Epoch 18/40\n",
      "2875/2875 [==============================] - 131s 46ms/step - loss: 0.3929 - acc: 0.8351 - val_loss: 0.3438 - val_acc: 0.8728\n",
      "Epoch 19/40\n",
      "2875/2875 [==============================] - 134s 47ms/step - loss: 0.3670 - acc: 0.8567 - val_loss: 0.3457 - val_acc: 0.8592\n",
      "Epoch 20/40\n",
      "2875/2875 [==============================] - 127s 44ms/step - loss: 0.3579 - acc: 0.8504 - val_loss: 0.3483 - val_acc: 0.8655\n",
      "Epoch 21/40\n",
      "2875/2875 [==============================] - 123s 43ms/step - loss: 0.3549 - acc: 0.8563 - val_loss: 0.3836 - val_acc: 0.8530\n",
      "Epoch 22/40\n",
      "2875/2875 [==============================] - 123s 43ms/step - loss: 0.3508 - acc: 0.8574 - val_loss: 0.3505 - val_acc: 0.8676\n",
      "Epoch 23/40\n",
      "2875/2875 [==============================] - 123s 43ms/step - loss: 0.3203 - acc: 0.8737 - val_loss: 0.3628 - val_acc: 0.8707\n",
      "Epoch 24/40\n",
      "2875/2875 [==============================] - 128s 44ms/step - loss: 0.3169 - acc: 0.8744 - val_loss: 0.3453 - val_acc: 0.8780\n",
      "Epoch 25/40\n",
      "2875/2875 [==============================] - 131s 46ms/step - loss: 0.3094 - acc: 0.8793 - val_loss: 0.3839 - val_acc: 0.8770\n",
      "Epoch 26/40\n",
      "2875/2875 [==============================] - 127s 44ms/step - loss: 0.3020 - acc: 0.8849 - val_loss: 0.3458 - val_acc: 0.8759\n",
      "Epoch 27/40\n",
      "2875/2875 [==============================] - 124s 43ms/step - loss: 0.2977 - acc: 0.8790 - val_loss: 0.3207 - val_acc: 0.8738\n",
      "Epoch 28/40\n",
      "2875/2875 [==============================] - 123s 43ms/step - loss: 0.2739 - acc: 0.8963 - val_loss: 0.3963 - val_acc: 0.8603\n",
      "Epoch 29/40\n",
      "2875/2875 [==============================] - 124s 43ms/step - loss: 0.2920 - acc: 0.8856 - val_loss: 0.3712 - val_acc: 0.8561\n",
      "Epoch 30/40\n",
      "2875/2875 [==============================] - 124s 43ms/step - loss: 0.2758 - acc: 0.8894 - val_loss: 0.3206 - val_acc: 0.8843\n",
      "Epoch 31/40\n",
      "2875/2875 [==============================] - 131s 46ms/step - loss: 0.2694 - acc: 0.8995 - val_loss: 0.3423 - val_acc: 0.8822\n",
      "Epoch 32/40\n",
      "2875/2875 [==============================] - 126s 44ms/step - loss: 0.2683 - acc: 0.8981 - val_loss: 0.3251 - val_acc: 0.8759\n",
      "Epoch 33/40\n",
      "2875/2875 [==============================] - 128s 45ms/step - loss: 0.2478 - acc: 0.9030 - val_loss: 0.3447 - val_acc: 0.8853\n",
      "Epoch 34/40\n",
      "2875/2875 [==============================] - 129s 45ms/step - loss: 0.2312 - acc: 0.9144 - val_loss: 0.3359 - val_acc: 0.8822\n",
      "Epoch 35/40\n",
      "2875/2875 [==============================] - 133s 46ms/step - loss: 0.2424 - acc: 0.9054 - val_loss: 0.3425 - val_acc: 0.8832\n",
      "Epoch 36/40\n",
      "2875/2875 [==============================] - 131s 46ms/step - loss: 0.2378 - acc: 0.9089 - val_loss: 0.3509 - val_acc: 0.8728\n",
      "Epoch 37/40\n",
      "2875/2875 [==============================] - 129s 45ms/step - loss: 0.2182 - acc: 0.9186 - val_loss: 0.3472 - val_acc: 0.8697\n",
      "Epoch 38/40\n",
      "2875/2875 [==============================] - 134s 47ms/step - loss: 0.2115 - acc: 0.9179 - val_loss: 0.3511 - val_acc: 0.8843\n",
      "Epoch 39/40\n",
      "2432/2875 [========================>.....] - ETA: 17s - loss: 0.2157 - acc: 0.9198"
     ]
    }
   ],
   "source": [
    "# Keep track of the runtime:\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model:\n",
    "result = model.fit(X_array,\n",
    "                    y_train,\n",
    "                    batch_size = 64,\n",
    "                    epochs = 40,\n",
    "                    verbose = 1,\n",
    "                   validation_data = (X_test_array, y_test))\n",
    "\n",
    "# Print the runtime:\n",
    "print('Runtime: ', round((time.time() - start_time)/60, 3), ' minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Training Plots:\n",
    "Training accuracy and loss functions vs. epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot accuracy over epochs\n",
    "learning_plots(title = 'Model Accuracy', \n",
    "               metric = 'acc', \n",
    "               val_metric = 'val_acc', \n",
    "               y_label = 'Accuracy')\n",
    "\n",
    "# Plot loss score over epoch\n",
    "learning_plots(title = 'Model Loss Score', \n",
    "               metric = 'loss', \n",
    "               val_metric = 'val_loss', \n",
    "               y_label = 'Loss Score',\n",
    "              c_train = 'green',\n",
    "              c_test = 'orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on Unseen Data:\n",
    "Now that the model has been fit, lets see if we can use it to detect some planets in data not seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "y_unseen = model.predict_classes(array_unseen)\n",
    "# Predict probabilities\n",
    "pred_proba = model.predict_proba(array_unseen)\n",
    "\n",
    "# make df of true labels and index\n",
    "true_y_unseen = c4_holdout['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the analyze_results function\n",
    "results_df, confusion_df = analyze_results(predictions = y_unseen, \n",
    "                                           y_test = true_y_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot auc-roc curve\n",
    "plot_roc(true_y_unseen, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
