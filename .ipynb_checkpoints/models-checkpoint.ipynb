{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_planets = pd.read_csv('../clean_planet_data/non_null_planets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kep3 = pd.read_csv('../clean_planet_data/clean_cut_kepc3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2c1 = pd.read_csv('../clean_planet_data/clean_cut_k2c1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Training Set:\n",
    "Mixing confirmed planets into data so the model can learn what they are like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5087, 3199)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kep3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1265, 3915)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_planets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1265, 3199)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cut out the extra data to compare across the same timeline\n",
    "join_planets = has_planets.iloc[:,:3199]\n",
    "join_planets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the dataframes have the same column names\n",
    "join_planets.columns = kep3.columns\n",
    "\n",
    "# label the confirmed planet systems with 1\n",
    "join_planets['LABEL'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KIC 10000941</td>\n",
       "      <td>1</td>\n",
       "      <td>52605.582031</td>\n",
       "      <td>52609.445312</td>\n",
       "      <td>52598.464844</td>\n",
       "      <td>52600.964844</td>\n",
       "      <td>52589.683594</td>\n",
       "      <td>52578.382812</td>\n",
       "      <td>52567.902344</td>\n",
       "      <td>52567.406250</td>\n",
       "      <td>...</td>\n",
       "      <td>52763.519531</td>\n",
       "      <td>52767.398438</td>\n",
       "      <td>52766.816406</td>\n",
       "      <td>52747.269531</td>\n",
       "      <td>52755.199219</td>\n",
       "      <td>52752.093750</td>\n",
       "      <td>52728.089844</td>\n",
       "      <td>52747.636719</td>\n",
       "      <td>52724.042969</td>\n",
       "      <td>52721.351562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KIC 10001368</td>\n",
       "      <td>1</td>\n",
       "      <td>34893.937500</td>\n",
       "      <td>34898.949219</td>\n",
       "      <td>34890.667969</td>\n",
       "      <td>34893.171875</td>\n",
       "      <td>34888.085938</td>\n",
       "      <td>34893.332031</td>\n",
       "      <td>34888.773438</td>\n",
       "      <td>34881.898438</td>\n",
       "      <td>...</td>\n",
       "      <td>34896.562500</td>\n",
       "      <td>34892.875000</td>\n",
       "      <td>34886.449219</td>\n",
       "      <td>34889.011719</td>\n",
       "      <td>34887.082031</td>\n",
       "      <td>34890.953125</td>\n",
       "      <td>34883.921875</td>\n",
       "      <td>34878.972656</td>\n",
       "      <td>34884.617188</td>\n",
       "      <td>34884.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KIC 10001893</td>\n",
       "      <td>1</td>\n",
       "      <td>6546.915039</td>\n",
       "      <td>6553.417480</td>\n",
       "      <td>6561.237793</td>\n",
       "      <td>6550.333008</td>\n",
       "      <td>6545.250977</td>\n",
       "      <td>6557.640625</td>\n",
       "      <td>6546.570312</td>\n",
       "      <td>6544.990723</td>\n",
       "      <td>...</td>\n",
       "      <td>6558.052246</td>\n",
       "      <td>6558.196777</td>\n",
       "      <td>6559.018066</td>\n",
       "      <td>6539.165039</td>\n",
       "      <td>6556.107910</td>\n",
       "      <td>6549.238281</td>\n",
       "      <td>6547.344727</td>\n",
       "      <td>6547.125977</td>\n",
       "      <td>6543.914062</td>\n",
       "      <td>6548.813477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KIC 10002866</td>\n",
       "      <td>1</td>\n",
       "      <td>13770.859375</td>\n",
       "      <td>13767.226562</td>\n",
       "      <td>13774.398438</td>\n",
       "      <td>13777.831055</td>\n",
       "      <td>13790.148438</td>\n",
       "      <td>13795.668945</td>\n",
       "      <td>13798.778320</td>\n",
       "      <td>13800.320312</td>\n",
       "      <td>...</td>\n",
       "      <td>13813.326172</td>\n",
       "      <td>13809.694336</td>\n",
       "      <td>13818.818359</td>\n",
       "      <td>13810.759766</td>\n",
       "      <td>13818.966797</td>\n",
       "      <td>13821.005859</td>\n",
       "      <td>13805.796875</td>\n",
       "      <td>13812.212891</td>\n",
       "      <td>13812.047852</td>\n",
       "      <td>13798.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KIC 10004519</td>\n",
       "      <td>1</td>\n",
       "      <td>10071.524414</td>\n",
       "      <td>10073.680664</td>\n",
       "      <td>10071.700195</td>\n",
       "      <td>10065.617188</td>\n",
       "      <td>10070.639648</td>\n",
       "      <td>10065.191406</td>\n",
       "      <td>10072.930664</td>\n",
       "      <td>10071.879883</td>\n",
       "      <td>...</td>\n",
       "      <td>10066.993164</td>\n",
       "      <td>10065.714844</td>\n",
       "      <td>10065.252930</td>\n",
       "      <td>10062.077148</td>\n",
       "      <td>10068.188477</td>\n",
       "      <td>10067.022461</td>\n",
       "      <td>10065.424805</td>\n",
       "      <td>10065.816406</td>\n",
       "      <td>10065.026367</td>\n",
       "      <td>10061.316406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  LABEL        FLUX.1        FLUX.2        FLUX.3  \\\n",
       "0  KIC 10000941      1  52605.582031  52609.445312  52598.464844   \n",
       "1  KIC 10001368      1  34893.937500  34898.949219  34890.667969   \n",
       "2  KIC 10001893      1   6546.915039   6553.417480   6561.237793   \n",
       "3  KIC 10002866      1  13770.859375  13767.226562  13774.398438   \n",
       "4  KIC 10004519      1  10071.524414  10073.680664  10071.700195   \n",
       "\n",
       "         FLUX.4        FLUX.5        FLUX.6        FLUX.7        FLUX.8  \\\n",
       "0  52600.964844  52589.683594  52578.382812  52567.902344  52567.406250   \n",
       "1  34893.171875  34888.085938  34893.332031  34888.773438  34881.898438   \n",
       "2   6550.333008   6545.250977   6557.640625   6546.570312   6544.990723   \n",
       "3  13777.831055  13790.148438  13795.668945  13798.778320  13800.320312   \n",
       "4  10065.617188  10070.639648  10065.191406  10072.930664  10071.879883   \n",
       "\n",
       "       ...          FLUX.3188     FLUX.3189     FLUX.3190     FLUX.3191  \\\n",
       "0      ...       52763.519531  52767.398438  52766.816406  52747.269531   \n",
       "1      ...       34896.562500  34892.875000  34886.449219  34889.011719   \n",
       "2      ...        6558.052246   6558.196777   6559.018066   6539.165039   \n",
       "3      ...       13813.326172  13809.694336  13818.818359  13810.759766   \n",
       "4      ...       10066.993164  10065.714844  10065.252930  10062.077148   \n",
       "\n",
       "      FLUX.3192     FLUX.3193     FLUX.3194     FLUX.3195     FLUX.3196  \\\n",
       "0  52755.199219  52752.093750  52728.089844  52747.636719  52724.042969   \n",
       "1  34887.082031  34890.953125  34883.921875  34878.972656  34884.617188   \n",
       "2   6556.107910   6549.238281   6547.344727   6547.125977   6543.914062   \n",
       "3  13818.966797  13821.005859  13805.796875  13812.212891  13812.047852   \n",
       "4  10068.188477  10067.022461  10065.424805  10065.816406  10065.026367   \n",
       "\n",
       "      FLUX.3197  \n",
       "0  52721.351562  \n",
       "1  34884.703125  \n",
       "2   6548.813477  \n",
       "3  13798.031250  \n",
       "4  10061.316406  \n",
       "\n",
       "[5 rows x 3199 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df = pd.concat([join_planets, kep3], axis = 0)\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline accuracy\n",
    "master_df['LABEL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7421782178217822"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_acc = 1302 / 5050\n",
    "1 - base_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make X and y\n",
    "X = master_df.iloc[:, 2:]\n",
    "y = master_df['LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things to tune over\n",
    "#     number of layers\n",
    "#     order of layers\n",
    "#     filters\n",
    "#     filter size\n",
    "#     nodes\n",
    "#     regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array = np.array(X_train)\n",
    "X_test_array = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array = np.expand_dims(X_array, axis = 2)\n",
    "X_test_array = np.expand_dims(X_test_array, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layer.\n",
    "model.add(Conv1D(filters = 10,      # number of filters\n",
    "                 kernel_size = (50),  # filter size\n",
    "                 activation = 'relu',\n",
    "                 input_shape = (3197, 1))) # dimensions of training data\n",
    "\n",
    "# Pooling layer.\n",
    "model.add(MaxPooling1D(pool_size = (5))) # by default, MaxPool will select the stride so the areas we pool will not overlap.\n",
    "\n",
    "# More convo & pooling layers?\n",
    "\n",
    "# regularize\n",
    "#     do I really want to be regularizing the convo and pooling layers if I want to increase its sensitivity?\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# In order to go from a convolutional/pooling layer, we have to organize our neurons.\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer.\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(0.5)) # regularization\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4764/4764 [==============================] - 11s 2ms/step - loss: 3.3732 - acc: 0.7899\n",
      "Epoch 2/10\n",
      "4764/4764 [==============================] - 10s 2ms/step - loss: 3.3055 - acc: 0.7949\n",
      "Epoch 3/10\n",
      "4764/4764 [==============================] - 10s 2ms/step - loss: 3.3055 - acc: 0.7949\n",
      "Epoch 4/10\n",
      "1600/4764 [=========>....................] - ETA: 6s - loss: 3.2236 - acc: 0.8000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-541dc3a031cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           verbose = 1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_array,\n",
    "          y_train,\n",
    "          batch_size = 64,\n",
    "          epochs = 10,\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1588/1588 [==============================] - 1s 654us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.2987286161715796, 0.7953400503778337]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Evaluate model on test data\n",
    "score = model.evaluate(X_test_array, y_test, verbose = 1)\n",
    "labels = model.metrics_names\n",
    "\n",
    "score\n",
    "# labels\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot loss over time.\n",
    "# plt.figure()\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='best')\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # What is the best way to do this?\n",
    "# undersample?\n",
    "# oversample?\n",
    "# What is the best ratio?\n",
    "# will this affect my result/ my false positive rate?\n",
    "\n",
    "# change columns of kep3 so you can join it with the planet data\n",
    "#     make sure there are no gaps in the confirmed planets data\n",
    "#     or the other data\n",
    "#     cut down dfs to be the right size\n",
    "#     do I want to remove the confimed planets already in the kep3 set in case they are repeats?\n",
    "\n",
    "# is it possible that some of the planets don't pass in front of their stars for the 66 days I'm looking at?\n",
    "#     what proportion of exoplanets have orbits of less than 66 days?\n",
    "\n",
    "# how am I going to deal with the nulls?\n",
    "#     skip to the next nearest non-null value?\n",
    "#     how many nulls in a row are there?\n",
    "#     if this happens to almost all confirmed planets, its possible that the network may learn to find these \"skips\"\n",
    "#         should I then just drop any rows with too many consecutive nans? \n",
    "#         Pretty much every one has a string of at least 40 consecutive nans\n",
    "#     mean imputation may have a logical case here\n",
    "#         it would make sense that the level of light is between previous value and the next one + random noise\n",
    "#         what about for longer strings of missing values \n",
    "#         mean imputation could be good for avoiding creating false signals because of its smoothing effect\n",
    "#         the disadvantages of mean imputation may not be important because I am basically using neural networks for pattern detection\n",
    "#     maybe if it is a long string of missing values you want to skip to the next real data, \n",
    "#         mark if that had happened so I could tell if it contributes to false positives\n",
    "#     drop rows with more than 150 nulls? there are only 8\n",
    "#         1134    666\n",
    "#         752     408\n",
    "#         851     408\n",
    "#         1105    408\n",
    "#         441     408\n",
    "#         832     285\n",
    "#         871     230\n",
    "#         762     230\n",
    "\n",
    "# definitely get data on whether it is a binary star system or not\n",
    "#     how to feed these single features to the neural networks to help with pattern detection?\n",
    "\n",
    "# normalize the light curves"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
