{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Modeling Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "# Set random seed to ensure reproducible results\n",
    "rand_seed = 112\n",
    "seed(rand_seed)\n",
    "set_random_seed(rand_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_planets = pd.read_csv('../clean_planet_data/clean_labeled_planets_seed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4_kep = pd.read_csv('../clean_planet_data/clean_labeled_c4_kep_seed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has_planets = pd.read_csv('https://hkvbeg.bn.files.1drv.com/y4mb-PSrD6ZisUltffu15Ka3BXb_DrfmCPvaKYTWhbahR2pnLr1x6VpRjSWeKzor3RD_qlL7tuaSg_Hb07umXqRc6uqMWwrwW0tBAEhIasLErimEru4S8H-cvw2fhOfIG0_RVyeGKsO859mj3y7EwFFw0B3qXy7szqPs92nvZ1fJ2K1MFegUtjfDN_og-T1DpLN/clean_labeled_planets_seed.csv?download&psid=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c4_kep = pd.read_csv('https://hkveeg.bn.files.1drv.com/y4m7mHQxUOaHeIegxylT-Kq6i8hoEDZ_0XRCGTFBmi5Ba1QMm3ZRmRKWf9GJphOQFVWR8dSrqqiuYzEWOTKt5Etvku-hVFf_5Ns92TGL72X4KaOI2Z6awQ253woinxn3ER-EL_8hbp2hyCozbu0sWdAiLKWRZbjZcLwoExg5K5CyS1-gIsSsIP3xjCZxJ-69KN4/clean_labeled_c4_kep_seed.csv?download&psid=1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Preprocessing Data:\n",
    "### Mix confirmed planets into data so the model can learn what they are like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7648\n",
       "1      65\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c4_kep['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cut out the extra data to compare across the same timeline (~3200 points)\n",
    "join_planets = has_planets.iloc[:,:3199]\n",
    "\n",
    "# split c4_kep to add to training data\n",
    "# to_train_on = c4_kep.head(2705).iloc[:,:3199] # 2705, 1205\n",
    "# to_train_on.columns = join_planets.columns\n",
    "\n",
    "# set aside the last 5000 stars as a holdout set\n",
    "# c4_holdout = c4_kep.tail(5000).iloc[:,:3199]\n",
    "# c4_holdout.columns = join_planets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select stars to train on, then set aside the rest as'unseen' data\n",
    "to_train_on = c4_kep.sample(2705, random_state=rand_seed).iloc[:,:3199] # 2705\n",
    "\n",
    "c4_holdout = c4_kep.iloc[:,:3199]\n",
    "\n",
    "# c4_kep[c4_kep['star_name'] not in to_train_on['star_name']]\n",
    "for _ in c4_holdout['star_name']:\n",
    "    if _ in to_train_on['star_name']:\n",
    "        c4_holdout.drop(index=_, inplace=True)\n",
    "\n",
    "c4_holdout.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Put training data together into master_df\n",
    "master_df = pd.concat([join_planets, to_train_on], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Acc:  0.3045843045843046\n",
      "0    2685\n",
      "1    1176\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate Baseline Accuracy\n",
    "val_count = master_df['label'].value_counts()\n",
    "base_acc = val_count[1] / val_count.sum()\n",
    "\n",
    "print('Baseline Acc: ', base_acc)\n",
    "print(val_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "Normalize the light curves so that stars of different brightnesses can be compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make X and y\n",
    "X = master_df.iloc[:, 2:]\n",
    "y = master_df['label']\n",
    "\n",
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate StandardScaler as ss\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose to scale each lightcurve row (rather than columns)\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "\n",
    "# Scaling\n",
    "scaled_df = ss.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(scaled_df, columns=X_train.columns)\n",
    "\n",
    "test_scaled_df = ss.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(test_scaled_df, columns=X_test.columns)\n",
    "\n",
    "# Transpose back to normal\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into an array and then change the dimensions\n",
    "X_array = np.array(X_train)\n",
    "X_array = np.expand_dims(X_array, axis = 2)\n",
    "\n",
    "# do this for the test set too\n",
    "X_test_array = np.array(X_test)\n",
    "X_test_array = np.expand_dims(X_test_array, axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Unseen Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice out the light curve\n",
    "unseen_data = c4_holdout.iloc[:,2:3199]\n",
    "\n",
    "# Scale\n",
    "unseen_data = unseen_data.T # transpose to scale each lightcurve row (rather than columns)\n",
    "\n",
    "scaled_unseen = ss.fit_transform(unseen_data)\n",
    "unseen_data = pd.DataFrame(scaled_unseen, columns=unseen_data.columns)\n",
    "\n",
    "unseen_data = unseen_data.T # Transpose back to normal\n",
    "\n",
    "# Change the dimensions so it can be put through the neural network\n",
    "array_unseen = np.array(unseen_data)\n",
    "array_unseen = np.expand_dims(array_unseen, axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Define Functions for Evaluating the Results Later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be used later to show how the model learned over the epochs\n",
    "\n",
    "def learning_plots(title, metric, val_metric, y_label, c_train='#1f77b4', c_test='orange'):\n",
    "\n",
    "    # Instantiate plot\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot metric of interest\n",
    "    plt.plot(result.history[metric], color = c_train)\n",
    "    plt.plot(result.history[val_metric], color = c_test)\n",
    "\n",
    "    # Set title\n",
    "    plt.title(title)\n",
    "\n",
    "    # Set axis labels\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlabel('Epoch (# of iterations)')\n",
    "\n",
    "    # Add a legend\n",
    "    plt.legend(['Train', 'Test'], loc='best')\n",
    "\n",
    "    # Plot girdlines:\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be used for showing the evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(predictions, y_test): #, all_results):\n",
    "\n",
    "\n",
    "    # Calculate \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "    total = (tp + tn + fp + fn)\n",
    "\n",
    "    \n",
    "    index_labels = ['Accuracy', 'Sensitivity', 'Specificity', 'Precision']\n",
    "    scores = pd.DataFrame(index = index_labels, columns=['Results'])\n",
    "    \n",
    "# Calculate results\n",
    "    decimals = 3\n",
    "\n",
    "    scores.loc['Accuracy'] = round((tp+tn) / (total), decimals)\n",
    "    scores.loc['Sensitivity'] = round(tp / (tp+fn), decimals)\n",
    "    scores.loc['Specificity'] = round(tn / (tn+fp), decimals)\n",
    "    scores.loc['Precision'] = round(tp / (tp+fp), decimals)\n",
    "\n",
    "    # Display the rounded results\n",
    "    display(scores)\n",
    "    \n",
    "# Calculate values for the confusion matrix\n",
    "\n",
    "    confusion = pd.DataFrame(index= ['Pred. Positive','Pred. Negative', 'Total'])\n",
    "\n",
    "    confusion['Act. Positive'] = tp, fn, (tp + fn)\n",
    "    confusion['Act. Negative'] = fp, tn, (fp + tn)\n",
    "\n",
    "    confusion['Total'] = (tp + fp), (fn + tn), total\n",
    "\n",
    "    display(confusion)\n",
    "    \n",
    "    print((tp + fp), 'predicted to have planets', '\\n',\n",
    "    tp, 'true positive planet stars predicted', '\\n',\n",
    "    round(tp/(tp+fn)*100, 3), '% of all true planets', '\\n') \n",
    "    \n",
    "    # Rate of planets in predictions\n",
    "    tp_rate = (tp / (tp + fp))\n",
    "    # Rate of planets in all unseen test set\n",
    "    all_rate = (tp + fn) / total\n",
    "    \n",
    "    print(round(tp_rate / all_rate, 3), 'times better than chance')\n",
    "    \n",
    "    # False positive rate\n",
    "    print(round(fp/(tp+fp)*100, 3), '% false positive rate')\n",
    "    \n",
    "    return scores, confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be used to plot the auc-roc curve when evaluating the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_roc(y_test, y_hat_proba):\n",
    "# Plot ROC-AUC curve\n",
    "\n",
    "    # Generate False positive rate and True positive rate\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_hat_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot settings\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    line_width = 4\n",
    "    \n",
    "    # Title and labels\n",
    "    plt.title('ROC Curve', fontsize=25, position = (0.2,1))\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    \n",
    "    # Gridlines\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.plot(fpr, tpr, lw = line_width)\n",
    "    plt.plot([0, 1], [0,1], lw = line_width, linestyle = '--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Neural Network Modeling:\n",
    "### Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional and layer.\n",
    "model.add(Conv1D(filters = 15, # tuned for 15\n",
    "                 kernel_size = (20),  # filter size, tuned for 20\n",
    "                 activation = 'relu',\n",
    "                 input_shape = (3197, 1))) # dimensions of training data\n",
    "\n",
    "# model.add(MaxPooling1D(pool_size = (1)))\n",
    "\n",
    "# Convolutional layer\n",
    "model.add(Conv1D(filters = 20, \n",
    "                 kernel_size = 30, # best so far 30\n",
    "                 activation = 'relu'))\n",
    "\n",
    "# model.add(MaxPooling1D(pool_size = (1)))\n",
    "\n",
    "# Convolutional layer\n",
    "model.add(Conv1D(filters = 10, # best so far 10\n",
    "                 kernel_size = 60, # best so far 60\n",
    "                 activation = 'relu'))\n",
    "\n",
    "# Convolutional layer\n",
    "model.add(Conv1D(filters = 20, \n",
    "                 kernel_size = 20,\n",
    "                 activation = 'relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pooling:\n",
    "model.add(MaxPooling1D(pool_size = (3))) # best so far 3\n",
    "model.add(Dropout(0.3)) # best so far .2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convolutional layer\n",
    "model.add(Conv1D(filters = 20, \n",
    "                 kernel_size = 10,\n",
    "                 activation = 'relu'))\n",
    "\n",
    "# Convolutional layer\n",
    "model.add(Conv1D(filters = 7, # tuned for 7, new-\n",
    "                 kernel_size = 20, # tuned for 20, new-\n",
    "                 activation = 'relu'))\n",
    "\n",
    "# Pooling layer.\n",
    "model.add(MaxPooling1D(pool_size = (5))) # best so far 5\n",
    "model.add(Dropout(0.4)) # regularization tuned for .25, confirmed 2nd round\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convolutional layer\n",
    "model.add(Conv1D(filters = 10, # tuned to 10, confirmed 2nd round\n",
    "                 kernel_size = 30, # tuned to 10, second round ~30\n",
    "                 activation = 'relu'))\n",
    "\n",
    "# model.add(Conv1D(filters = 7,\n",
    "#                  kernel_size = 5, # 5?\n",
    "#                  activation = 'relu'))\n",
    "\n",
    "# Pooling layer.\n",
    "model.add(MaxPooling1D(pool_size = (5))) # tuned to 5, confirmed 2nd round\n",
    "model.add(Dropout(0.5)) # regularization tuned to .5\n",
    "\n",
    "\n",
    "\n",
    "# Organize neurons by flattening.\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected hidden layers.\n",
    "\n",
    "# Hidden layer 1\n",
    "model.add(Dense(2500, activation = 'relu')) # 1st round- 2500, .7 drop\n",
    "model.add(Dropout(0.5)) # best so far .4\n",
    "\n",
    "model.add(Dense(1500, activation = 'relu')), # 1st round- 1000, .7 drop, 2nd best so far 1500, .4 drop\n",
    "model.add(Dropout(0.5)) # best so far .5?\n",
    "\n",
    "# model.add(Dense(500, activation = 'relu'))\n",
    "\n",
    "\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# Setting learning rate and decay\n",
    "learn_rate = 0.001\n",
    "# # x% reduction in learing_rate by epoch: coef_by_epoch\n",
    "# coef_reduce = .75\n",
    "# coef_by_epoch = 30\n",
    "\n",
    "# Calculate decay\n",
    "decay = 0 #(learn_rate - (coef_reduce * learn_rate)) / coef_by_epoch\n",
    "\n",
    "# Changing adam optimization parameters\n",
    "optimizers.adam(lr = learn_rate, decay = decay)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2895 samples, validate on 966 samples\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "# Keep track of the runtime:\n",
    "start_time = time.time()\n",
    "\n",
    "# Set the random state\n",
    "rand_seed = 112\n",
    "seed(rand_seed)\n",
    "set_random_seed(rand_seed)\n",
    "\n",
    "# Fit the model:\n",
    "result = model.fit(X_array,\n",
    "                    y_train,\n",
    "                    batch_size = 64,\n",
    "                    epochs = 20,\n",
    "                    verbose = 1,\n",
    "                   validation_data = (X_test_array, y_test))\n",
    "\n",
    "# Print the runtime:\n",
    "print('Runtime: ', round((time.time() - start_time)/60, 3), ' minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Training Plots:\n",
    "Training accuracy and loss functions vs. epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot loss score over epoch\n",
    "learning_plots(title = 'Model Loss Score', \n",
    "               metric = 'loss', \n",
    "               val_metric = 'val_loss', \n",
    "               y_label = 'Loss Score',\n",
    "              c_train = 'green',\n",
    "              c_test = 'orange')\n",
    "\n",
    "# Plot accuracy over epochs\n",
    "learning_plots(title = 'Model Accuracy', \n",
    "               metric = 'acc', \n",
    "               val_metric = 'val_acc', \n",
    "               y_label = 'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on Unseen Data:\n",
    "Now that the model has been fit, lets see if we can use it to detect some planets in data not seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "y_unseen = model.predict_classes(array_unseen)\n",
    "# Predict probabilities\n",
    "pred_proba = model.predict_proba(array_unseen)\n",
    "\n",
    "# make df of true labels and index\n",
    "true_y_unseen = c4_holdout['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the analyze_results function\n",
    "results_df, confusion_df = analyze_results(predictions = y_unseen, \n",
    "                                           y_test = true_y_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot auc-roc curve\n",
    "plot_roc(true_y_unseen, pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
